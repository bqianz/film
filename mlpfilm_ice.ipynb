{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f98096-bf83-41be-a7d5-72f7794cb779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2675d831-08ab-43f7-b625-cfab6c6128f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_width = 32\n",
    "hidden_nblocks = 4\n",
    "train_max_epoch = 30\n",
    "max_iterations = 1\n",
    "\n",
    "chip_size = 32\n",
    "data_root = \"geomorph_data\"\n",
    "# data_root = \"geomorph_data_test\"\n",
    "n_channels = len(os.listdir(data_root))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "L2_param = 1e-5\n",
    "\n",
    "label_name = \"visible_ice\"\n",
    "num_classes = 5\n",
    "output_size = num_classes\n",
    "\n",
    "sm = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4881e7a-a053-4a5c-bfda-53eae0c93971",
   "metadata": {},
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(input)\n",
    "print(target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b59b6ad-d7be-476f-b4bd-c5d6ce57e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0678, -0.5621, -0.4612],\n",
      "        [ 0.2020,  1.0318, -0.8818]])\n",
      "tensor([[0.8682, 0.0626, 0.0692],\n",
      "        [0.2754, 0.6314, 0.0932]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=-1)\n",
    "# m = nn.Sigmoid()\n",
    "input = torch.randn(2,3)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629fd05b-9fa8-4502-b8cb-e0892a432591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "        def __init__(self, input_size, output_size = 1, hidden_width = 20, hidden_nblocks = 2):\n",
    "            super(mlp, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_width = hidden_width\n",
    "            self.hidden_nblocks = hidden_nblocks\n",
    "            \n",
    "            self.fc1 = nn.Linear(self.input_size, self.hidden_width)\n",
    "            self.fc2 = nn.Linear(self.hidden_width,self.hidden_width)\n",
    "            self.fc3 = nn.Linear(self.hidden_width, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.end= torch.nn.Softmax(dim = -1) ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "            self.dropout = nn.Dropout(0.25)\n",
    "            \n",
    "        def forward(self, x, film_params):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            \n",
    "            for i in range(self.hidden_nblocks):\n",
    "                out = self.fc2(out)\n",
    "                \n",
    "                # ------- film layer -----------\n",
    "                start = i * hidden_width * 2\n",
    "                mid = start + hidden_width\n",
    "                end = mid + hidden_width\n",
    "                \n",
    "                gamma = film_params[:, start : mid]\n",
    "                beta = film_params[:, mid : end]\n",
    "                \n",
    "#                 print(out.shape)\n",
    "#                 print(gamma.shape)\n",
    "#                 print(beta.shape)\n",
    "                \n",
    "                out = out * gamma\n",
    "                out += beta\n",
    "                # ------- film layer -----------\n",
    "                # out = self.dropout(out)\n",
    "                out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            # out = self.end(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905bba3-9233-41cb-8ed6-ffa9087f4e8f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93742035-18c5-42bc-b9e8-86134e61c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2837\n",
      "566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>borehole</th>\n",
       "      <th>depth</th>\n",
       "      <th>frozen</th>\n",
       "      <th>cryostructures</th>\n",
       "      <th>visible_ice</th>\n",
       "      <th>ASTM_2488</th>\n",
       "      <th>materials</th>\n",
       "      <th>...</th>\n",
       "      <th>top_of_interval</th>\n",
       "      <th>bottom_of_interval</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>month_cyclic</th>\n",
       "      <th>lat_norm</th>\n",
       "      <th>lng_norm</th>\n",
       "      <th>depth_norm</th>\n",
       "      <th>year_norm</th>\n",
       "      <th>month_cyclic_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOPSOIL</td>\n",
       "      <td>Organics</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>-1.024190</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pure ice</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Ice</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>-0.835900</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>SW-SM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>-0.553466</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>GW-GM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>0.387982</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.16105</td>\n",
       "      <td>-133.08880</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-12</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>GP-GM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.437795</td>\n",
       "      <td>1.842620</td>\n",
       "      <td>-0.741756</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude                  time   borehole  depth  frozen  \\\n",
       "0  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   0.15       0   \n",
       "1  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   0.85       1   \n",
       "2  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   1.90       1   \n",
       "3  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   5.40       1   \n",
       "4  69.16105 -133.08880  2012-03-21T00:00:00Z  0170-1-12   1.20       1   \n",
       "\n",
       "  cryostructures     visible_ice ASTM_2488    materials  ...  top_of_interval  \\\n",
       "0            NaN             NaN   TOPSOIL     Organics  ...              0.0   \n",
       "1            NaN        Pure ice       ICE          Ice  ...              0.3   \n",
       "2             Nf  No visible ice     SW-SM  Coarse till  ...              1.4   \n",
       "3             Nf  No visible ice     GW-GM  Coarse till  ...              2.4   \n",
       "4             Nf  No visible ice     GP-GM  Coarse till  ...              0.0   \n",
       "\n",
       "   bottom_of_interval  month  year  month_cyclic  lat_norm  lng_norm  \\\n",
       "0                 0.3      3  2012             3  1.439946  1.851455   \n",
       "1                 1.4      3  2012             3  1.439946  1.851455   \n",
       "2                 2.4      3  2012             3  1.439946  1.851455   \n",
       "3                 8.4      3  2012             3  1.439946  1.851455   \n",
       "4                 2.4      3  2012             3  1.437795  1.842620   \n",
       "\n",
       "   depth_norm  year_norm  month_cyclic_norm  \n",
       "0   -1.024190  -1.164992          -1.225295  \n",
       "1   -0.835900  -1.164992          -1.225295  \n",
       "2   -0.553466  -1.164992          -1.225295  \n",
       "3    0.387982  -1.164992          -1.225295  \n",
       "4   -0.741756  -1.164992          -1.225295  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "def normalize(values):\n",
    "    # zero mean, unit variance\n",
    "    value_mean = values.mean()\n",
    "    value_std = values.std()\n",
    "    return (values-values_mean)/values_std\n",
    "\n",
    "def normalize_maxmin(values):\n",
    "    # range from 0 to 1\n",
    "    (values-values.min())/(values.max()-values.min())\n",
    "\n",
    "\n",
    "# def get_scaler(data):\n",
    "#     scaler = StandardScaler()\n",
    "#     print(data)\n",
    "#     scaler.fit(data)\n",
    "#     return scaler\n",
    "    \n",
    "def preprocess_df(df):\n",
    "    # convert timecodes to year and month columns\n",
    "    datetimes = pd.to_datetime(df['time'])\n",
    "    df['month'] = datetimes.dt.month\n",
    "    df['year'] = datetimes.dt.year\n",
    "\n",
    "    df['month_cyclic'] = 7 - abs(df['month'] - 7)\n",
    "    \n",
    "    data = df[['latitude', 'longitude', 'depth', 'year', 'month_cyclic']]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    df[['lat_norm', 'lng_norm', 'depth_norm', 'year_norm', 'month_cyclic_norm']] = scaler.transform(df[['latitude', 'longitude', 'depth', 'year', 'month_cyclic']])\n",
    "    \n",
    "    return scaler\n",
    "\n",
    "\n",
    "#     df['lat_norm'] = normalize(df['latitude'])\n",
    "#     df['lng_norm'] = normalize(df['longitude'])\n",
    "#     df['depth_norm'],  = normalize(df['depth'])\n",
    "#     df['year_norm'] = normalize(df['year'])\n",
    "#     df['month_cyclic_norm'] = normalize(df['month_cyclic'])\n",
    "\n",
    "df = pd.read_csv('data_stephen_fix_header.csv', header=[0])\n",
    "scaler = preprocess_df(df)\n",
    "    \n",
    "print(df.shape[0])\n",
    "print(df['borehole'].nunique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf25c9ad-dfd3-4503-ba42-c3ad78c5370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.44755\n",
      "68.36933\n",
      "-132.89346\n",
      "-133.82843\n"
     ]
    }
   ],
   "source": [
    "print(df.latitude.max())\n",
    "print(df.latitude.min())\n",
    "print(df.longitude.max())\n",
    "print(df.longitude.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b03030-dd00-4063-948c-24493aafdd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>borehole</th>\n",
       "      <th>depth</th>\n",
       "      <th>frozen</th>\n",
       "      <th>cryostructures</th>\n",
       "      <th>visible_ice</th>\n",
       "      <th>ASTM_2488</th>\n",
       "      <th>materials</th>\n",
       "      <th>...</th>\n",
       "      <th>top_of_interval</th>\n",
       "      <th>bottom_of_interval</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>month_cyclic</th>\n",
       "      <th>lat_norm</th>\n",
       "      <th>lng_norm</th>\n",
       "      <th>depth_norm</th>\n",
       "      <th>year_norm</th>\n",
       "      <th>month_cyclic_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>68.38262</td>\n",
       "      <td>-133.71211</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH15</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf/Nbn</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.499167</td>\n",
       "      <td>-0.938559</td>\n",
       "      <td>0.401431</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>68.38262</td>\n",
       "      <td>-133.71211</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH15</td>\n",
       "      <td>8.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Nbn</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.499167</td>\n",
       "      <td>-0.938559</td>\n",
       "      <td>1.262184</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>68.38386</td>\n",
       "      <td>-133.70967</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>Organics</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.494489</td>\n",
       "      <td>-0.927672</td>\n",
       "      <td>-1.051089</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>68.38386</td>\n",
       "      <td>-133.70967</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.494489</td>\n",
       "      <td>-0.927672</td>\n",
       "      <td>-0.970393</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>68.38386</td>\n",
       "      <td>-133.70967</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH16</td>\n",
       "      <td>4.85</td>\n",
       "      <td>1</td>\n",
       "      <td>Nbn</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.494489</td>\n",
       "      <td>-0.927672</td>\n",
       "      <td>0.240040</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude                  time           borehole  depth  \\\n",
       "2832  68.38262 -133.71211  2013-04-27T00:00:00Z  W14103137-S6-BH15   5.45   \n",
       "2833  68.38262 -133.71211  2013-04-27T00:00:00Z  W14103137-S6-BH15   8.65   \n",
       "2834  68.38386 -133.70967  2013-04-27T00:00:00Z  W14103137-S6-BH16   0.05   \n",
       "2835  68.38386 -133.70967  2013-04-27T00:00:00Z  W14103137-S6-BH16   0.35   \n",
       "2836  68.38386 -133.70967  2013-04-27T00:00:00Z  W14103137-S6-BH16   4.85   \n",
       "\n",
       "      frozen cryostructures     visible_ice ASTM_2488 materials  ...  \\\n",
       "2832       1         Nf/Nbn  No visible ice       NaN      Till  ...   \n",
       "2833       1            Nbn  No visible ice       NaN      Till  ...   \n",
       "2834       0            NaN  No visible ice  ORGANICS  Organics  ...   \n",
       "2835       0            NaN  No visible ice       NaN      Till  ...   \n",
       "2836       1            Nbn  No visible ice       NaN      Till  ...   \n",
       "\n",
       "      top_of_interval  bottom_of_interval  month  year  month_cyclic  \\\n",
       "2832              2.7                 8.2      4  2013             4   \n",
       "2833              8.2                 9.1      4  2013             4   \n",
       "2834              0.0                 0.1      4  2013             4   \n",
       "2835              0.1                 0.6      4  2013             4   \n",
       "2836              0.6                 9.1      4  2013             4   \n",
       "\n",
       "      lat_norm  lng_norm  depth_norm  year_norm  month_cyclic_norm  \n",
       "2832 -1.499167 -0.938559    0.401431  -0.319053           0.736422  \n",
       "2833 -1.499167 -0.938559    1.262184  -0.319053           0.736422  \n",
       "2834 -1.494489 -0.927672   -1.051089  -0.319053           0.736422  \n",
       "2835 -1.494489 -0.927672   -0.970393  -0.319053           0.736422  \n",
       "2836 -1.494489 -0.927672    0.240040  -0.319053           0.736422  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visible_ice'].replace(['None'], 'No visible ice', regex=True, inplace=True)\n",
    "\n",
    "ordered_ice = ['No visible ice', 'Low', \"Medium to high\", 'High', 'Pure ice']\n",
    "df['visible_ice'] = pd.Series(pd.Categorical(df['visible_ice'], categories=ordered_ice, ordered=True))\n",
    "\n",
    "df2 = df.dropna(subset=['visible_ice'])\n",
    "\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c4e13c5-b8cf-4a80-8029-451c643cc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['visible_ice_code'] =  df['visible_ice'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e70e70-5bc9-4523-94fc-f70f64f18f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NaN, 'Pure ice', 'No visible ice', 'High', 'Medium to high', 'Low']\n",
      "Categories (5, object): ['No visible ice' < 'Low' < 'Medium to high' < 'High' < 'Pure ice']\n"
     ]
    }
   ],
   "source": [
    "print(df['visible_ice'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6839a20-7655-4882-83d2-a2e4e1abf18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  4,  0,  3,  2,  1], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visible_ice_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e66d4b-f80d-4295-8f97-38f6603c4ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check None values have been replaced\n",
    "len(df2[df2['visible_ice'] == 'None'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00107137-4ac0-49a9-bae8-7e5aa1883ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pure ice', 'No visible ice', 'High', 'Medium to high', 'Low']\n",
      "Categories (5, object): ['No visible ice' < 'Low' < 'Medium to high' < 'High' < 'Pure ice']\n",
      "[4 0 3 2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-b83c4bbc5a30>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['visible_ice_code'] =  df2['visible_ice'].cat.codes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1             Pure ice\n",
       "2       No visible ice\n",
       "3       No visible ice\n",
       "4       No visible ice\n",
       "5       No visible ice\n",
       "             ...      \n",
       "2832    No visible ice\n",
       "2833    No visible ice\n",
       "2834    No visible ice\n",
       "2835    No visible ice\n",
       "2836    No visible ice\n",
       "Name: visible_ice, Length: 2752, dtype: category\n",
       "Categories (5, object): ['No visible ice' < 'Low' < 'Medium to high' < 'High' < 'Pure ice']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['visible_ice_code'] =  df2['visible_ice'].cat.codes\n",
    "print(df2['visible_ice'].unique())\n",
    "print(df2['visible_ice_code'].unique())\n",
    "df2['visible_ice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c3d6e0-5ed8-4d93-ad53-e6a84b8a007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visible_ice = pd.get_dummies(df2.visible_ice)\n",
    "# bin_visible_ice = (~visible_ice['No visible ice'].astype('bool')).astype('int')\n",
    "# bin_visible_ice.value_counts()\n",
    "\n",
    "# df2['visible_ice'] = bin_visible_ice\n",
    "\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1837f5df-ee84-4d0d-9942-14b948a37934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.dropna(subset=['materials'])\n",
    "df3['materials'].replace(['ICE'], 'Ice', regex=True, inplace=True)\n",
    "df3['materials'].replace(['ice'], 'Ice', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba8d5fb-1a64-4fea-a69a-20b744e097a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_materials = pd.get_dummies(df3.materials)\n",
    "df3['material_ice'] = dm_materials['Ice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ecd3dc-6e04-48d5-84b0-6b3ce4251644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = pd.read_csv(r\"C:\\Users\\mouju\\Desktop\\film\\components_analysis\\df_unique.csv\", header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c3c456-b700-46cd-9a6d-52872ba14aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Geo90Dataset(Dataset):\n",
    "    def __init__(self, data_root, df, base_lat, base_lng, chip_size=32):\n",
    "        \n",
    "        self.base_lat = base_lat\n",
    "        self.base_lng = base_lng\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        self.chip_size = chip_size\n",
    "        \n",
    "        self.trans = transforms.ToTensor()\n",
    "        \n",
    "        self.n_channels = len(os.listdir(data_root))\n",
    "        self.preloaded = torch.ones(self.n_channels, 6000, 6000)\n",
    "        \n",
    "        for i, file in enumerate(os.listdir(data_root)):\n",
    "            # name = file.split('_')[0]\n",
    "            # print(name)\n",
    "            \n",
    "            I = np.array(Image.open(data_root + os.path.sep + file))\n",
    "            # I = plt.imread(data_root + os.path.sep + file)\n",
    "            \n",
    "#             print(I.max())\n",
    "#             print(I.min())\n",
    "            \n",
    "#             # normalize\n",
    "#             I = (((I - I.min()) / (I.max() - I.min())) * 255.9).astype(np.uint8)\n",
    "#             print(I.max())\n",
    "#             print(I.min())\n",
    "            \n",
    "            self.preloaded[i] = self.trans(I)\n",
    "            print(f'loaded {file}')\n",
    "            \n",
    "        \n",
    "        \n",
    "        print('Dataset initialized')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # bh_id = row.at['borehole']\n",
    "        lat = row.at['latitude']\n",
    "        lng = row.at['longitude']\n",
    "        \n",
    "        # print(lat, lng)\n",
    "        \n",
    "\n",
    "        pixel_len = 5/6000\n",
    "        \n",
    "\n",
    "        lat_index_start = np.round((self.base_lat - lat) / pixel_len - self.chip_size/2).astype(int)\n",
    "        lat_index_end = lat_index_start + self.chip_size\n",
    "        \n",
    "        lng_index_start = np.round((lng - self.base_lng) / pixel_len - self.chip_size/2).astype(int)\n",
    "        lng_index_end = lng_index_start + self.chip_size\n",
    "        \n",
    "        image = self.preloaded[:, lat_index_start:lat_index_end,lng_index_start:lng_index_end]\n",
    "        \n",
    "        \n",
    "        # surface = torch.tensor(row.filter(['depth'])).float()\n",
    "        surface = torch.tensor(row.filter(['depth_norm', 'month_cyclic_norm', 'lat_norm', 'lng_norm', 'year_norm'])).float()\n",
    "        \n",
    "        frozen = torch.tensor(row.at['frozen']).float()\n",
    "        \n",
    "        # visible_ice = torch.tensor(row.at['visible_ice']).float()\n",
    "        visible_ice = torch.tensor(row.at['visible_ice_code']).long()\n",
    "        \n",
    "        # material_ice = torch.tensor(row.at['material_ice']).float()\n",
    "        \n",
    "        return {'image': image, 'surface_data': surface, 'frozen': frozen,  'visible_ice': visible_ice} #'material_ice': material_ice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d26ba2b-3c00-436f-a175-933f8b97eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded aspect-cosine_90M_n65w135.tif\n",
      "loaded aspect-sine_90M_n65w135.tif\n",
      "loaded aspect_90M_n65w135.tif\n",
      "loaded convergence_90M_n65w135.tif\n",
      "loaded cti_90M_n65w135.tif\n",
      "loaded dev-magnitude_90M_n65w135.tif\n",
      "loaded dev-scale_90M_n65w135.tif\n",
      "loaded dxx_90M_n65w135.tif\n",
      "loaded dxy_90M_n65w135.tif\n",
      "loaded dx_90M_n65w135.tif\n",
      "loaded dyy_90M_n65w135.tif\n",
      "loaded dy_90M_n65w135.tif\n",
      "loaded eastness_90M_n65w135.tif\n",
      "loaded elev-stdev_90M_n65w135.tif\n",
      "loaded northness_90M_n65w135.tif\n",
      "loaded pcurv_90M_n65w135.tif\n",
      "loaded rough-magnitude_90M_n65w135.tif\n",
      "loaded rough-scale_90M_n65w135.tif\n",
      "loaded roughness_90M_n65w135.tif\n",
      "loaded slope_90M_n65w135.tif\n",
      "loaded spi_90M_n65w135.tif\n",
      "loaded tcurv_90M_n65w135.tif\n",
      "loaded tpi_90M_n65w135.tif\n",
      "loaded tri_90M_n65w135.tif\n",
      "loaded vrm_90M_n65w135.tif\n",
      "Dataset initialized\n"
     ]
    }
   ],
   "source": [
    "base_lat = 70\n",
    "base_lng = -135\n",
    "\n",
    "loaded_dataset = Geo90Dataset(data_root, df2, base_lat, base_lng, chip_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "153cc6da-674e-4a77-b3ca-1324682c7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_dataset[0]['image'].shape)\n",
    "\n",
    "# chips_root = \"geomorph_data_test_chips\"\n",
    "\n",
    "# for i, data in enumerate(test_dataset):\n",
    "    \n",
    "#     save_image(data['image'], os.path.join(\"geomorph_data_test_chips\", f'{i:04d}.png'))\n",
    "#     # np.save(os.path.join(chips_root, f'{i:04d}.npy'), data['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b0df9-d51d-4bb3-9658-7a49e95bc6a6",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f46b0-7537-4ceb-8f96-263c007e97fd",
   "metadata": {},
   "source": [
    "## FiLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214c4911-bcfb-43a2-b41b-b01949690b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_film_params = hidden_width * hidden_nblocks * 2\n",
    "\n",
    "# generator = resnet18(n_channels, n_film_params)\n",
    "\n",
    "def train_model(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    # loss: binary cross entropy\n",
    "\n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    # print(gen_model)\n",
    "\n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    net_model = mlp(input_size[0],output_size, hidden_width, hidden_nblocks).to(device)\n",
    "    \n",
    "    gen_optimizer = torch.optim.Adam(gen_model.parameters(), weight_decay = L2_param)\n",
    "    net_optimizer = torch.optim.Adam(net_model.parameters(), weight_decay = L2_param)\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "\n",
    "    # --------- check back propagation ----------- -\n",
    "    # net_model.fc1.weight.register_hook(lambda x: print('grad accumulated in mlp fc1'))\n",
    "    # gen_first_layer = gen_model.encoder.blocks[0].blocks[0].blocks[0].conv\n",
    "    # gen_first_layer.weight.register_hook(lambda x: print('grad accumulated in resnet first layer'))\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        # ------------ train -----------------\n",
    "        gen_model.train()\n",
    "        net_model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            \n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            net_optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            gen_optimizer.step()\n",
    "            net_optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        gen_model.eval()\n",
    "        net_model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # TODO: exammine film_params gradients / readup pytorch\n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "\n",
    "        torch.save(gen_model.state_dict(), os.path.join('mlp-resnet-models/', 'gen-epoch-{}.pt'.format(epoch+1)))\n",
    "        torch.save(net_model.state_dict(), os.path.join('mlp-resnet-models/', 'net-epoch-{}.pt'.format(epoch+1)))\n",
    "\n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "## Test model\n",
    "\n",
    "def test_model(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    net_model = mlp(input_size[0], output_size, hidden_width, hidden_nblocks)\n",
    "\n",
    "    gen_model.load_state_dict(torch.load('mlp-resnet-models/gen-epoch-{}.pt'.format(ind+1)))\n",
    "    net_model.load_state_dict(torch.load('mlp-resnet-models/net-epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    gen_model.eval()\n",
    "    net_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            \n",
    "            output = sm(predicted)\n",
    "            # print(output)\n",
    "            \n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "            #predicted = torch.round(output)\n",
    "            # print(predicted.shape)\n",
    "            \n",
    "            y_test.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            \n",
    "#             predicted = torch.squeeze(predicted)\n",
    "\n",
    "#             predicted = torch.round(predicted)\n",
    "#             # print(predicted.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             lb = labels.tolist()\n",
    "#             pr = predicted.tolist()\n",
    "#             y_test.extend(lb)\n",
    "#             y_pred.extend(pr)\n",
    "    \n",
    "    arr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
    "    return arr_accuracy, scores, gen_model, net_model\n",
    "\n",
    "\n",
    "#     print(confusion_matrix(y_test,y_pred))\n",
    "#     print(classification_report(y_test,y_pred))\n",
    "#     print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "## Pure MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8b5b0-1039-4c76-93e4-0f90b60d87be",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43c02928-f9c5-4b2a-8ef7-d8a2de4a4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_pure(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(mlp_pure, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_size = hidden_width\n",
    "            self.hidden_nblocks = hidden_nblocks\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size,self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.end = torch.nn.Softmax(dim=-1) ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            # print(out.shape)\n",
    "            \n",
    "            for i in range(self.hidden_nblocks):\n",
    "                out = self.fc2(out)\n",
    "                out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            # out = self.end(out)\n",
    "            return out\n",
    "\n",
    "def train_mlp(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    surface_model = mlp_pure(input_size[0],output_size)\n",
    "    \n",
    "    surface_model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(surface_model.parameters(), weight_decay = L2_param)\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        surface_model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            surface_data, labels = data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            predicted = surface_model(surface_data)\n",
    "            \n",
    "#             print(predicted.squeeze().shape)\n",
    "#             print(labels.shape)\n",
    "            \n",
    "            \n",
    "            # squeeze: return tensor with all dimensions of size 1 removed\n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        surface_model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            surface_data, labels = data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            predicted = surface_model(surface_data)\n",
    "            \n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "\n",
    "        torch.save(surface_model.state_dict(), os.path.join('mlp-models/', 'epoch-{}.pt'.format(epoch+1)))\n",
    "    \n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "        \n",
    "    return epoch_loss\n",
    "        \n",
    "def test_mlp(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    \n",
    "    surface_model = mlp_pure(input_size[0],output_size)\n",
    "    surface_model.load_state_dict(torch.load('mlp-models/epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    surface_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    surface_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        y_cert = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            surface_data, labels = data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            output = surface_model(surface_data)\n",
    "            \n",
    "            output = sm(output)\n",
    "            # print(output)\n",
    "            \n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "            certainty = max_results.values\n",
    "            #predicted = torch.round(output)\n",
    "            # print(predicted.shape)\n",
    "            \n",
    "            y_test.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            y_cert.extend(certainty.tolist())\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "#     print(y_test)\n",
    "#     print(y_pred)\n",
    "    with open(\"mlp-certainty/iteration_{}.txt\".format(it), \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(y_cert, fp)\n",
    "    #with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "        #b = pickle.load(fp)\n",
    "    arr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
    "    return arr_accuracy, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cfb6b-c5ca-4fdd-81e9-571685a86522",
   "metadata": {},
   "source": [
    "## Multiple Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44629f3-5888-4eb0-8f54-cfd63f455c54",
   "metadata": {},
   "source": [
    "### Discard samples with invalid values in image chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc861435-97ab-4095-9760-4b797477daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2752\n",
      "2717\n"
     ]
    }
   ],
   "source": [
    "valid_ind = []\n",
    "for i, data in enumerate(loaded_dataset):\n",
    "    image = data['image']\n",
    "    ind  = (image == -9999)\n",
    "    if ~torch.any(ind):\n",
    "        valid_ind.append(i)\n",
    "\n",
    "full_dataset = torch.utils.data.Subset(loaded_dataset, valid_ind)\n",
    "\n",
    "\n",
    "print(len(loaded_dataset))\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba299154-57ac-4e30-bf2e-74e41e3fc64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "# batchsize can cause error when last leftover batchsize is 1, batchnorm cannot function on 1 sample data\n",
    "batchsize = 20\n",
    "while(train_size % batchsize == 1):\n",
    "    batchsize+=1\n",
    "print(batchsize)\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb6971-4f9e-409e-b8ee-9ebe27a3cfae",
   "metadata": {},
   "source": [
    "## Scale of image chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e37318c4-ff02-48e0-aa8c-c5a708eb0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = full_dataset[0]['image']\n",
    "# n_samples = len(train_data)\n",
    "# n_channels = list(image.shape)[0]\n",
    "\n",
    "# scalers = []\n",
    "# for i in range(n_channels):\n",
    "#     print(i)\n",
    "#     scaler = StandardScaler()\n",
    "#     X = torch.empty((n_samples, chip_size, chip_size))\n",
    "    \n",
    "#     for j, data in enumerate(train_data):\n",
    "#         #print(data['image'][i].shape)\n",
    "#         # print(X[j].shape)\n",
    "#         X[j] = data['image'][i]\n",
    "#     X = torch.reshape(X, (-1,1))\n",
    "#     #print(X)\n",
    "#     # break;\n",
    "#     scaler.fit(X)\n",
    "#     scalers.append(scaler)\n",
    "    \n",
    "#     def scale_data(subset):\n",
    "#         for data in subset:\n",
    "#             X = data['image'][i]\n",
    "#             X_flat = torch.reshape(X, (-1,1))\n",
    "            \n",
    "#             X_trans = scaler.transform(X_flat)\n",
    "#             data['image'][i] = torch.reshape(torch.Tensor(X_trans), (chip_size, chip_size))\n",
    "    \n",
    "#     scale_data(train_data)\n",
    "#     scale_data(test_data)\n",
    "#     print(\"Channel {} scaled.\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f7a6d03-a8b0-4c0f-b562-415f30deb0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1: running loss: 1.44492, validation loss: 1.33790\n",
      "epoch  2: running loss: 1.38418, validation loss: 1.36370\n",
      "epoch  3: running loss: 1.37790, validation loss: 1.34009\n",
      "epoch  4: running loss: 1.36814, validation loss: 1.34767\n",
      "epoch  5: running loss: 1.36356, validation loss: 1.36283\n",
      "epoch  6: running loss: 1.35359, validation loss: 1.34349\n",
      "epoch  7: running loss: 1.34880, validation loss: 1.37193\n",
      "epoch  8: running loss: 1.34593, validation loss: 1.32500\n",
      "epoch  9: running loss: 1.32860, validation loss: 1.32999\n",
      "epoch 10: running loss: 1.32442, validation loss: 1.39019\n",
      "epoch 11: running loss: 1.32344, validation loss: 1.40285\n",
      "epoch 12: running loss: 1.30567, validation loss: 1.29770\n",
      "epoch 13: running loss: 1.29412, validation loss: 1.33545\n",
      "epoch 14: running loss: 1.29161, validation loss: 1.31909\n",
      "epoch 15: running loss: 1.27990, validation loss: 1.32816\n",
      "epoch 16: running loss: 1.27747, validation loss: 1.35986\n",
      "epoch 17: running loss: 1.26488, validation loss: 1.33308\n",
      "epoch 18: running loss: 1.25725, validation loss: 1.31577\n",
      "epoch 19: running loss: 1.24251, validation loss: 1.41120\n",
      "epoch 20: running loss: 1.24291, validation loss: 1.32075\n",
      "epoch 21: running loss: 1.22494, validation loss: 1.36365\n",
      "epoch 22: running loss: 1.22006, validation loss: 1.34077\n",
      "epoch 23: running loss: 1.20718, validation loss: 1.35378\n",
      "epoch 24: running loss: 1.19974, validation loss: 1.39254\n",
      "epoch 25: running loss: 1.18904, validation loss: 1.29758\n",
      "epoch 26: running loss: 1.19041, validation loss: 1.35592\n",
      "epoch 27: running loss: 1.18078, validation loss: 1.33506\n",
      "epoch 28: running loss: 1.17063, validation loss: 1.35738\n",
      "epoch 29: running loss: 1.16548, validation loss: 1.38312\n",
      "epoch 30: running loss: 1.16412, validation loss: 1.36436\n",
      "Finished Training\n",
      "epoch 25 model selected\n",
      "iteration 1 elapsed time: 133.41357564926147, accuracy : 0.3786764705882353\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 1\n",
    "results = np.zeros([max_iterations, num_classes*4 + 1])\n",
    "# trainloader, testloader = prepare_dataloader(full_dataset)\n",
    "\n",
    "for it in range(max_iterations):\n",
    "    start = time.time()\n",
    "    \n",
    "    # mlp\n",
    "#     epoch_loss_mlp = train_mlp(trainloader,testloader, print_epochs = True, loss_fn = nn.CrossEntropyLoss())\n",
    "#     acc, scores = test_mlp(epoch_loss_mlp, print_model_epoch = True)\n",
    "    \n",
    "    #     # ------- mlp-resnet film \n",
    "    epoch_loss = train_model(trainloader, testloader, print_epochs=True, loss_fn = nn.CrossEntropyLoss())\n",
    "    acc, scores, gen_model, net_model = test_model(epoch_loss, print_model_epoch = True)\n",
    "    \n",
    "    # scores = precision, recall, fscore, support\n",
    "    results[it, 0] = acc\n",
    "    \n",
    "    for j, score in enumerate(scores):\n",
    "        start_ind = 1 + j*num_classes\n",
    "        results[it, start_ind: start_ind + num_classes] = score\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print('iteration {} elapsed time: {}, accuracy : {}'.format(it+1, end-start, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c5555c3-2ed2-4e85-9c9b-0c3985f51881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 model selected\n"
     ]
    }
   ],
   "source": [
    "acc, scores, gen_model, net_model = test_model(epoch_loss, print_model_epoch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c9a2433-e48a-459f-bc98-a1d16f330f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533981</td>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.359477</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382199</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>0.425656</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1  support\n",
       "0   0.533981  0.270936  0.359477    203.0\n",
       "1   0.382199  0.480263  0.425656    152.0\n",
       "2   0.315789  0.553191  0.402062    141.0\n",
       "3   0.000000  0.000000  0.000000     15.0\n",
       "4   0.000000  0.000000  0.000000     33.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall   f1  support\n",
       "0        0.0     0.0  0.0      0.0\n",
       "1        0.0     0.0  0.0      0.0\n",
       "2        0.0     0.0  0.0      0.0\n",
       "3        0.0     0.0  0.0      0.0\n",
       "4        0.0     0.0  0.0      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.3786764705882353, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "def display_table(scores):\n",
    "    df = np.reshape(scores, [num_classes,4], order ='F')\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    # df.style.set_table_attributes(\"style='display:inline'\").set_caption(mode)\n",
    "    \n",
    "    df.columns = ['precision', 'recall', 'f1', 'support']\n",
    "    # df.index = ['unfrozen', 'frozen']\n",
    "    # df.index = ['Visible ice', 'No visible ice']\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "def display_results(results):\n",
    "    mean = np.mean(results, axis=0)\n",
    "    std = np.std(results, axis=0)\n",
    "    \n",
    "    print(\"mean\")\n",
    "    display_table(mean[1:])\n",
    "    \n",
    "    print(\"std\")\n",
    "    display_table(std[1:])\n",
    "    \n",
    "    print(\"Accuracy mean: {}, std: {}\".format(mean[0], std[0]))\n",
    "\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360fa50-304f-4e3b-b33a-51b9f820a580",
   "metadata": {},
   "source": [
    "## Display Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b51afa27-1fb7-4bf4-9da2-82b90a263657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df.depth.max())\n",
    "print(df.depth.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b8c1174-a942-4f78-8a9f-4d1bb0f8b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_max = 69.5\n",
    "latitude_min = 68.3\n",
    "longitude_max = -132.8\n",
    "longitude_min = -133.9\n",
    "\n",
    "n_lat = 80\n",
    "n_lng = 40\n",
    "\n",
    "\n",
    "lng_range = np.linspace(longitude_min, longitude_max, n_lng)\n",
    "lat_range = np.linspace(latitude_max, latitude_min, n_lat)\n",
    "depth_range = [1, 3, 5, 7, 9]\n",
    "n_depth = len(depth_range)\n",
    "\n",
    "grid_lng, grid_lat, grid_depth = np.meshgrid(lng_range, lat_range, depth_range)\n",
    "\n",
    "\n",
    "\n",
    "# e.g \n",
    "# grid_lng[0, :, 0] = [-133.9, ... -132.8]\n",
    "# grid_lat[:,0,0] = [69.5, ..., 68.3]\n",
    "\n",
    "# rows: latitude, columns: longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "760cb363-06ed-4756-a8a3-defd0f81da4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.5       , 69.48481013, 69.46962025, 69.45443038, 69.43924051,\n",
       "       69.42405063, 69.40886076, 69.39367089, 69.37848101, 69.36329114,\n",
       "       69.34810127, 69.33291139, 69.31772152, 69.30253165, 69.28734177,\n",
       "       69.2721519 , 69.25696203, 69.24177215, 69.22658228, 69.21139241,\n",
       "       69.19620253, 69.18101266, 69.16582278, 69.15063291, 69.13544304,\n",
       "       69.12025316, 69.10506329, 69.08987342, 69.07468354, 69.05949367,\n",
       "       69.0443038 , 69.02911392, 69.01392405, 68.99873418, 68.9835443 ,\n",
       "       68.96835443, 68.95316456, 68.93797468, 68.92278481, 68.90759494,\n",
       "       68.89240506, 68.87721519, 68.86202532, 68.84683544, 68.83164557,\n",
       "       68.8164557 , 68.80126582, 68.78607595, 68.77088608, 68.7556962 ,\n",
       "       68.74050633, 68.72531646, 68.71012658, 68.69493671, 68.67974684,\n",
       "       68.66455696, 68.64936709, 68.63417722, 68.61898734, 68.60379747,\n",
       "       68.58860759, 68.57341772, 68.55822785, 68.54303797, 68.5278481 ,\n",
       "       68.51265823, 68.49746835, 68.48227848, 68.46708861, 68.45189873,\n",
       "       68.43670886, 68.42151899, 68.40632911, 68.39113924, 68.37594937,\n",
       "       68.36075949, 68.34556962, 68.33037975, 68.31518987, 68.3       ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lat[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "946bd4b9-c52f-4c0c-aec0-db5dd6176c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = pd.DataFrame(columns=['latitude', 'longitude', 'depth', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9d4dce3-206c-4862-b6b9-18bf06583869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn['latitude'] = grid_lat.flatten()\n",
    "df_syn['longitude'] = grid_lng.flatten()\n",
    "df_syn['depth'] = grid_depth.flatten()\n",
    "df_syn['year'] = 2013\n",
    "df_syn['month'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aa90869-47cc-481f-b33e-e28f1bcb17ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>68.3</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>68.3</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>68.3</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>68.3</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>68.3</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  depth  year  month\n",
       "15995      68.3     -132.8      1  2013      3\n",
       "15996      68.3     -132.8      3  2013      3\n",
       "15997      68.3     -132.8      5  2013      3\n",
       "15998      68.3     -132.8      7  2013      3\n",
       "15999      68.3     -132.8      9  2013      3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca2e1789-890d-45cd-86a4-9cc1b2124194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  68.77996824, -133.50176278,    3.95760839, 2013.37715897,\n",
       "          3.62460345])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceb5256c-18c4-429c-b4d5-947a845e9f79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- month\nFeature names seen at fit time, yet now missing:\n- month_cyclic\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bc771dce0700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_syn_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_syn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    993\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \"\"\"\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    479\u001b[0m                 )\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     def _validate_data(\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- month\nFeature names seen at fit time, yet now missing:\n- month_cyclic\n"
     ]
    }
   ],
   "source": [
    "df_syn_scaled = scaler.transform(df_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f1e48-f5be-42cb-9002-f91d8404e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4d438-17cc-4b0c-bfee-e81fe41818d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'depth_norm', 'month_cyclic_norm', 'lat_norm', 'lng_norm', 'year_norm'\n",
    "df_syn_scaled = pd.DataFrame(df_syn_scaled, columns = ['lat_norm', 'lng_norm', 'depth_norm', 'year_norm', 'month_cyclic_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5172f5-7ad1-4c07-a939-95535cc88296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_scaled['frozen'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2106135-d7c1-4b1d-a144-2d04bc1ca3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_scaled['visible_ice_code'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e811d65-6c6e-4809-9551-2b038240dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_scaled['latitude'] = df_syn['latitude']\n",
    "df_syn_scaled['longitude'] = df_syn['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad2fc0-49fe-44e7-a127-a8775c9fc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19c21e-e319-46da-aca8-e07e7ee371e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lat = 70\n",
    "base_lng = -135\n",
    "\n",
    "loaded_dataset = Geo90Dataset(data_root, df_syn_scaled, base_lat, base_lng, chip_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d348ff1-579c-458f-93eb-b02baea54860",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ind = []\n",
    "for i, data in enumerate(loaded_dataset):\n",
    "    image = data['image']\n",
    "    ind  = (image == -9999)\n",
    "    if ~torch.any(ind):\n",
    "        valid_ind.append(i)\n",
    "\n",
    "full_dataset = torch.utils.data.Subset(loaded_dataset, valid_ind)\n",
    "\n",
    "\n",
    "print(len(loaded_dataset))\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102af55f-79ae-455f-b083-bace1d5961ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize can cause error when last leftover batchsize is 1, batchnorm cannot function on 1 sample data\n",
    "batchsize = 20\n",
    "\n",
    "# train_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "testloader = DataLoader(loaded_dataset, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abecd8-8e8d-4045-9a1c-50451537dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_syn_model(epoch_id, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = epoch_id\n",
    "    \n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    input_size = list(loaded_dataset[0]['surface_data'].size())\n",
    "    net_model = mlp(input_size[0], output_size, hidden_width, hidden_nblocks)\n",
    "    \n",
    "    print(net_model)\n",
    "\n",
    "    gen_model.load_state_dict(torch.load('mlp-resnet-models/gen-epoch-{}.pt'.format(ind+1)))\n",
    "    net_model.load_state_dict(torch.load('mlp-resnet-models/net-epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    gen_model.eval()\n",
    "    net_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            \n",
    "            output = sm(predicted)\n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "            #predicted = torch.round(output)\n",
    "            # print(predicted.shape)\n",
    "            y_pred.extend(predicted.tolist())\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28eafbc-7028-444d-b297-e7906a122d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = test_syn_model(17, print_model_epoch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc67001-562d-4a2b-98b1-40e5bdf1a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.array(predicted).reshape(n_lat, n_lng, n_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd27cc-6f8b-43eb-b2c0-d62444b2c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1220c4-88f1-44e2-a925-0eac5929465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8a0d6-6de8-4fce-b995-099c3d73f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ select model ---------\n",
    "ind = 40\n",
    "\n",
    "input_size = list(full_dataset[0]['surface_data'].size())\n",
    "\n",
    "surface_model = mlp_pure(input_size[0],output_size)\n",
    "\n",
    "surface_model.load_state_dict(torch.load('mlp-models/epoch-{}.pt'.format(ind+1)))\n",
    "\n",
    "surface_model.to(device)\n",
    "\n",
    "# surface_model = surface_model.float()\n",
    "\n",
    "print(\"epoch {} model selected\".format(ind+1))\n",
    "\n",
    "# evaluate model on synthetic set\n",
    "surface_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    y_cert = []\n",
    "    \n",
    "    surface_data= torch.from_numpy(df_syn).float().to(device)\n",
    "\n",
    "    # y_test.append(label.numpy().list())\n",
    "    # print(label.shape)\n",
    "    # print(images.shape)\n",
    "\n",
    "    output = surface_model(surface_data)\n",
    "\n",
    "    output = sm(output)\n",
    "    # print(output)\n",
    "    \n",
    "    # proxy for uncertainty\n",
    "    # cross entropy penalizes value for not being close to 1 when it's the right category\n",
    "    # saturate leading to overconfidence\n",
    "\n",
    "    max_results = torch.max(output, dim= -1)\n",
    "    predicted = max_results.indices\n",
    "    certainty = max_results.values\n",
    "\n",
    "predicted = predicted.reshape(n_lat, n_lng, n_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cf23c-e1e0-448e-a0e9-062ecb39fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predicted.npy', predicted.cpu())\n",
    "# with open('predicted.npy', 'wb') as f:\n",
    "#     np.save(f, predicted.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3deb01-0c75-4e46-8acb-78dcbdf67035",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da8f0d-d3d2-4bfd-ab92-e0fb060fea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted[:, :, 0].cpu())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84f41e-6256-4ef3-9664-a4ff26c867b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e80c1-699d-4e37-9153-57629f56614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2d = torch.sum(predicted, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48bfd7-9ea2-484e-b418-f5db6f7493de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_2d.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72896a9a-2a6c-4e8d-a78b-474415d64182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.colors import to_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b09b6a-96e3-4b97-81dd-2101e9710289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmplot as gp\n",
    "\n",
    "mean_lat = df2.latitude.unique().mean()\n",
    "mean_lng = df2.longitude.unique().mean()\n",
    "\n",
    "grid_lng_2d, grid_lat_2d = np.meshgrid(lng_range, lat_range)\n",
    "grid_lng_2d = grid_lng_2d.flatten()\n",
    "grid_lat_2d = grid_lat_2d.flatten()\n",
    "\n",
    "grid_lat_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f4bfd-1b83-4774-8fa0-83f9dc978cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean = cm.get_cmap('inferno',predicted_2d.max())\n",
    "\n",
    "predicted_2d = predicted_2d.flatten().cpu()\n",
    "color_ice = ocean(predicted_2d)\n",
    "len(color_ice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb1487-24e0-446b-b27d-538c47df6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_ice_hex = [None] * len(color_ice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11ca0e-2622-4ecd-b16c-fe88d3e76d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color in enumerate(color_ice):\n",
    "    color_ice_hex[i] = to_hex(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4699c-01e9-44cb-bfb8-550c21f75ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gp.GoogleMapPlotter(mean_lat, mean_lng, 8, apikey = \"AIzaSyBUVgOpJ5OP6L3Rsmtbzy1cTCegpyPAvF4\")\n",
    "# use \"maps javascript api\" credential\n",
    " \n",
    "gmap.scatter(grid_lat_2d, grid_lng_2d, s = 1000, c=color_ice_hex, marker=False) #, color='#3B0B39', size=40, marker=False)\n",
    "# gmap.heatmap(df2.latitude.tolist(), df2.longitude.tolist())  \n",
    "\n",
    "# gmap.scatter(grid_lat_2d[0:2], grid_lng_2d[0:2], s = 500, c=ocean[predicted_2d[0:2]])\n",
    "\n",
    "# Pass the absolute path\n",
    "now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "gmap.draw( \"map_ice{}.html\".format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866904e-fdc6-4889-9fb9-4af653fc9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lng_2d.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bdff7-6416-4068-b906-d31f96171af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2d.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576ea58-15e5-4c76-84a5-b42c4417e5d2",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22f050eb-fa12-404a-8d44-bdb3a113e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(testloader))\n",
    "\n",
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ac0ea32-d485-40ab-a987-8a2b125e6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_surfaces = batch['surface_data'].to('cpu')\n",
    "test_images = batch['image'].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "145c0f33-7b1f-4dcf-a42b-9f546a6e8935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(trainloader))\n",
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "455979e9-a7f0-4ad3-afd4-c01e4d8dfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_surfaces = batch['surface_data'].to('cpu')\n",
    "train_images = batch['image'].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "179e5115-c73b-4e0d-aa42-bc844a104626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp(\n",
       "  (fc1): Linear(in_features=5, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (end): Softmax(dim=-1)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.to('cpu')\n",
    "net_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7465cc90-ce11-4650-83c2-3a35701bb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85e6e263-097d-4b37-b5e1-48d6f194baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_gen = shap.DeepExplainer(gen_model, train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c62be1c9-df0d-49a7-bbe4-ba332ecca1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6451a262-d427-4593-a542-a4a6d1f5f40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcd9e132-52a6-4609-a0ac-2d28425a2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_fewer = test_images[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2fd490f-577b-46c2-a217-ba5a3be5754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 32, 32])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_fewer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "538cb467-65ae-447f-8b21-56454d68e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    }
   ],
   "source": [
    "shap_values = explainer_gen.shap_values(test_images_fewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b674706-d908-4c40-b95c-cdb844d2d98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a22ca0a-28ab-40c7-bf26-74c3fce6fa1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78601529-6728-4021-a627-61cff5a94b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82b53e15-63e0-4db3-a7b7-dfb640aeb141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_values[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bdbd5af-26d2-4b3a-8014-96a4a8c18ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_values[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9892e974-cca1-4cac-b5c4-488f00c3f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(test_images_fewer.numpy(), 1, -1), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "755a3a54-0c13-4251-a62c-8d20a6d750d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x9.33852 with 258 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the feature attributions\n",
    "shap.image_plot(shap_numpy, -test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8eef10d6-8b40-4218-8b67-3fe9104b4493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "610bd513-f8bb-4f66-9992-91a8b6e73c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_numpy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fe4da1e-ba9c-44e4-b0da-7eefb889e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_numpy[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de26caed-21c6-4a48-9c25-ea9e84b6e222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_numpy[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccd5792f-bc24-4814-931d-328021fc0fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_numpy[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be82fb5-c28f-426f-bc2f-d2deb5dae73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
