{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78f98096-bf83-41be-a7d5-72f7794cb779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2675d831-08ab-43f7-b625-cfab6c6128f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_width = 32\n",
    "hidden_nblocks = 4\n",
    "train_max_epoch = 50\n",
    "max_iterations = 10\n",
    "\n",
    "chip_size = 32\n",
    "data_root = \"geomorph_data\"\n",
    "# data_root = \"geomorph_data_test\"\n",
    "n_channels = len(os.listdir(data_root))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "L2_param = 1e-5\n",
    "\n",
    "label_name = \"visible_ice\"\n",
    "num_classes = 5\n",
    "output_size = num_classes\n",
    "\n",
    "sm = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddd8266e-da2e-4871-a8f4-7d37702f30bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4170, -1.1240, -0.2534, -0.9663,  0.0899],\n",
      "        [ 0.9121, -0.2216, -1.2080, -1.4477, -0.1897],\n",
      "        [ 0.7221,  0.9588,  0.2867,  0.8016,  0.1294]], requires_grad=True)\n",
      "tensor([2, 3, 2])\n",
      "tensor(2.0750, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(input)\n",
    "print(target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b59b6ad-d7be-476f-b4bd-c5d6ce57e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9454, -0.8951,  0.1970],\n",
      "        [ 0.0029, -0.5944,  1.0001]])\n",
      "tensor([[0.6128, 0.0973, 0.2899],\n",
      "        [0.2347, 0.1291, 0.6362]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=-1)\n",
    "# m = nn.Sigmoid()\n",
    "input = torch.randn(2,3)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "629fd05b-9fa8-4502-b8cb-e0892a432591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "        def __init__(self, input_size, output_size = 1, hidden_width = 20, hidden_nblocks = 2):\n",
    "            super(mlp, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_width = hidden_width\n",
    "            self.hidden_nblocks = hidden_nblocks\n",
    "            \n",
    "            self.fc1 = nn.Linear(self.input_size, self.hidden_width)\n",
    "            self.fc2 = nn.Linear(self.hidden_width,self.hidden_width)\n",
    "            self.fc3 = nn.Linear(self.hidden_width, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.end= torch.nn.Softmax(dim = -1) ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "            self.dropout = nn.Dropout(0.25)\n",
    "            \n",
    "        def forward(self, x, film_params):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            \n",
    "            for i in range(self.hidden_nblocks):\n",
    "                out = self.fc2(out)\n",
    "                \n",
    "                # ------- film layer -----------\n",
    "                start = i * hidden_width * 2\n",
    "                mid = start + hidden_width\n",
    "                end = mid + hidden_width\n",
    "                \n",
    "                gamma = film_params[:, start : mid]\n",
    "                beta = film_params[:, mid : end]\n",
    "                \n",
    "#                 print(out.shape)\n",
    "#                 print(gamma.shape)\n",
    "#                 print(beta.shape)\n",
    "                \n",
    "                out = out * gamma\n",
    "                out += beta\n",
    "                # ------- film layer -----------\n",
    "                # out = self.dropout(out)\n",
    "                out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            # out = self.end(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905bba3-9233-41cb-8ed6-ffa9087f4e8f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93742035-18c5-42bc-b9e8-86134e61c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2837\n",
      "566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>borehole</th>\n",
       "      <th>depth</th>\n",
       "      <th>frozen</th>\n",
       "      <th>cryostructures</th>\n",
       "      <th>visible_ice</th>\n",
       "      <th>ASTM_2488</th>\n",
       "      <th>materials</th>\n",
       "      <th>...</th>\n",
       "      <th>top_of_interval</th>\n",
       "      <th>bottom_of_interval</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>month_cyclic</th>\n",
       "      <th>lat_norm</th>\n",
       "      <th>lng_norm</th>\n",
       "      <th>depth_norm</th>\n",
       "      <th>year_norm</th>\n",
       "      <th>month_cyclic_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOPSOIL</td>\n",
       "      <td>Organics</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>-1.024190</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pure ice</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Ice</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>-0.835900</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>SW-SM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>-0.553466</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>GW-GM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.439946</td>\n",
       "      <td>1.851455</td>\n",
       "      <td>0.387982</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.16105</td>\n",
       "      <td>-133.08880</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-12</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>GP-GM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.437795</td>\n",
       "      <td>1.842620</td>\n",
       "      <td>-0.741756</td>\n",
       "      <td>-1.164992</td>\n",
       "      <td>-1.225295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude                  time   borehole  depth  frozen  \\\n",
       "0  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   0.15       0   \n",
       "1  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   0.85       1   \n",
       "2  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   1.90       1   \n",
       "3  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   5.40       1   \n",
       "4  69.16105 -133.08880  2012-03-21T00:00:00Z  0170-1-12   1.20       1   \n",
       "\n",
       "  cryostructures     visible_ice ASTM_2488    materials  ...  top_of_interval  \\\n",
       "0            NaN             NaN   TOPSOIL     Organics  ...              0.0   \n",
       "1            NaN        Pure ice       ICE          Ice  ...              0.3   \n",
       "2             Nf  No visible ice     SW-SM  Coarse till  ...              1.4   \n",
       "3             Nf  No visible ice     GW-GM  Coarse till  ...              2.4   \n",
       "4             Nf  No visible ice     GP-GM  Coarse till  ...              0.0   \n",
       "\n",
       "   bottom_of_interval  month  year  month_cyclic  lat_norm  lng_norm  \\\n",
       "0                 0.3      3  2012             3  1.439946  1.851455   \n",
       "1                 1.4      3  2012             3  1.439946  1.851455   \n",
       "2                 2.4      3  2012             3  1.439946  1.851455   \n",
       "3                 8.4      3  2012             3  1.439946  1.851455   \n",
       "4                 2.4      3  2012             3  1.437795  1.842620   \n",
       "\n",
       "   depth_norm  year_norm  month_cyclic_norm  \n",
       "0   -1.024190  -1.164992          -1.225295  \n",
       "1   -0.835900  -1.164992          -1.225295  \n",
       "2   -0.553466  -1.164992          -1.225295  \n",
       "3    0.387982  -1.164992          -1.225295  \n",
       "4   -0.741756  -1.164992          -1.225295  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "def normalize(values):\n",
    "    # zero mean, unit variance\n",
    "    value_mean = values.mean()\n",
    "    value_std = values.std()\n",
    "    return (values-values_mean)/values_std\n",
    "\n",
    "def normalize_maxmin(values):\n",
    "    # range from 0 to 1\n",
    "    (values-values.min())/(values.max()-values.min())\n",
    "\n",
    "\n",
    "def get_scaler(data):\n",
    "    scaler = StandardScaler()\n",
    "    print(data)\n",
    "    scaler.fit(data)\n",
    "    return scaler\n",
    "    \n",
    "def preprocess_df(df):\n",
    "    # convert timecodes to year and month columns\n",
    "    datetimes = pd.to_datetime(df['time'])\n",
    "    df['month'] = datetimes.dt.month\n",
    "    df['year'] = datetimes.dt.year\n",
    "\n",
    "    df['month_cyclic'] = 7 - abs(df['month'] - 7)\n",
    "    \n",
    "    data = df[['latitude', 'longitude', 'depth', 'year', 'month_cyclic']]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    df[['lat_norm', 'lng_norm', 'depth_norm', 'year_norm', 'month_cyclic_norm']] = scaler.transform(df[['latitude', 'longitude', 'depth', 'year', 'month_cyclic']])\n",
    "    \n",
    "    return scaler\n",
    "\n",
    "\n",
    "#     df['lat_norm'] = normalize(df['latitude'])\n",
    "#     df['lng_norm'] = normalize(df['longitude'])\n",
    "#     df['depth_norm'],  = normalize(df['depth'])\n",
    "#     df['year_norm'] = normalize(df['year'])\n",
    "#     df['month_cyclic_norm'] = normalize(df['month_cyclic'])\n",
    "\n",
    "df = pd.read_csv('data_stephen_fix_header.csv', header=[0])\n",
    "scaler = preprocess_df(df)\n",
    "    \n",
    "print(df.shape[0])\n",
    "print(df['borehole'].nunique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf25c9ad-dfd3-4503-ba42-c3ad78c5370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.44755\n",
      "68.36933\n",
      "-132.89346\n",
      "-133.82843\n"
     ]
    }
   ],
   "source": [
    "print(df.latitude.max())\n",
    "print(df.latitude.min())\n",
    "print(df.longitude.max())\n",
    "print(df.longitude.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10b03030-dd00-4063-948c-24493aafdd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>borehole</th>\n",
       "      <th>depth</th>\n",
       "      <th>frozen</th>\n",
       "      <th>cryostructures</th>\n",
       "      <th>visible_ice</th>\n",
       "      <th>ASTM_2488</th>\n",
       "      <th>materials</th>\n",
       "      <th>...</th>\n",
       "      <th>top_of_interval</th>\n",
       "      <th>bottom_of_interval</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>month_cyclic</th>\n",
       "      <th>lat_norm</th>\n",
       "      <th>lng_norm</th>\n",
       "      <th>depth_norm</th>\n",
       "      <th>year_norm</th>\n",
       "      <th>month_cyclic_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>68.38262</td>\n",
       "      <td>-133.71211</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH15</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf/Nbn</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.499167</td>\n",
       "      <td>-0.938559</td>\n",
       "      <td>0.401431</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>68.38262</td>\n",
       "      <td>-133.71211</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH15</td>\n",
       "      <td>8.65</td>\n",
       "      <td>1</td>\n",
       "      <td>Nbn</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.499167</td>\n",
       "      <td>-0.938559</td>\n",
       "      <td>1.262184</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>68.38386</td>\n",
       "      <td>-133.70967</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>Organics</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.494489</td>\n",
       "      <td>-0.927672</td>\n",
       "      <td>-1.051089</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>68.38386</td>\n",
       "      <td>-133.70967</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.494489</td>\n",
       "      <td>-0.927672</td>\n",
       "      <td>-0.970393</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>68.38386</td>\n",
       "      <td>-133.70967</td>\n",
       "      <td>2013-04-27T00:00:00Z</td>\n",
       "      <td>W14103137-S6-BH16</td>\n",
       "      <td>4.85</td>\n",
       "      <td>1</td>\n",
       "      <td>Nbn</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Till</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.494489</td>\n",
       "      <td>-0.927672</td>\n",
       "      <td>0.240040</td>\n",
       "      <td>-0.319053</td>\n",
       "      <td>0.736422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude                  time           borehole  depth  \\\n",
       "2832  68.38262 -133.71211  2013-04-27T00:00:00Z  W14103137-S6-BH15   5.45   \n",
       "2833  68.38262 -133.71211  2013-04-27T00:00:00Z  W14103137-S6-BH15   8.65   \n",
       "2834  68.38386 -133.70967  2013-04-27T00:00:00Z  W14103137-S6-BH16   0.05   \n",
       "2835  68.38386 -133.70967  2013-04-27T00:00:00Z  W14103137-S6-BH16   0.35   \n",
       "2836  68.38386 -133.70967  2013-04-27T00:00:00Z  W14103137-S6-BH16   4.85   \n",
       "\n",
       "      frozen cryostructures     visible_ice ASTM_2488 materials  ...  \\\n",
       "2832       1         Nf/Nbn  No visible ice       NaN      Till  ...   \n",
       "2833       1            Nbn  No visible ice       NaN      Till  ...   \n",
       "2834       0            NaN  No visible ice  ORGANICS  Organics  ...   \n",
       "2835       0            NaN  No visible ice       NaN      Till  ...   \n",
       "2836       1            Nbn  No visible ice       NaN      Till  ...   \n",
       "\n",
       "      top_of_interval  bottom_of_interval  month  year  month_cyclic  \\\n",
       "2832              2.7                 8.2      4  2013             4   \n",
       "2833              8.2                 9.1      4  2013             4   \n",
       "2834              0.0                 0.1      4  2013             4   \n",
       "2835              0.1                 0.6      4  2013             4   \n",
       "2836              0.6                 9.1      4  2013             4   \n",
       "\n",
       "      lat_norm  lng_norm  depth_norm  year_norm  month_cyclic_norm  \n",
       "2832 -1.499167 -0.938559    0.401431  -0.319053           0.736422  \n",
       "2833 -1.499167 -0.938559    1.262184  -0.319053           0.736422  \n",
       "2834 -1.494489 -0.927672   -1.051089  -0.319053           0.736422  \n",
       "2835 -1.494489 -0.927672   -0.970393  -0.319053           0.736422  \n",
       "2836 -1.494489 -0.927672    0.240040  -0.319053           0.736422  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visible_ice'].replace(['None'], 'No visible ice', regex=True, inplace=True)\n",
    "\n",
    "ordered_ice = ['No visible ice', 'Low', \"Medium to high\", 'High', 'Pure ice']\n",
    "df['visible_ice'] = pd.Series(pd.Categorical(df['visible_ice'], categories=ordered_ice, ordered=True))\n",
    "\n",
    "df2 = df.dropna(subset=['visible_ice'])\n",
    "\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5e66d4b-f80d-4295-8f97-38f6603c4ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check None values have been replaced\n",
    "len(df2[df2['visible_ice'] == 'None'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "00107137-4ac0-49a9-bae8-7e5aa1883ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pure ice', 'No visible ice', 'High', 'Medium to high', 'Low']\n",
      "Categories (5, object): ['No visible ice' < 'Low' < 'Medium to high' < 'High' < 'Pure ice']\n",
      "[4 0 3 2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1             Pure ice\n",
       "2       No visible ice\n",
       "3       No visible ice\n",
       "4       No visible ice\n",
       "5       No visible ice\n",
       "             ...      \n",
       "2832    No visible ice\n",
       "2833    No visible ice\n",
       "2834    No visible ice\n",
       "2835    No visible ice\n",
       "2836    No visible ice\n",
       "Name: visible_ice, Length: 2752, dtype: category\n",
       "Categories (5, object): ['No visible ice' < 'Low' < 'Medium to high' < 'High' < 'Pure ice']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['visible_ice_code'] =  df2['visible_ice'].cat.codes\n",
    "print(df2['visible_ice'].unique())\n",
    "print(df2['visible_ice_code'].unique())\n",
    "df2['visible_ice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21c3d6e0-5ed8-4d93-ad53-e6a84b8a007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visible_ice = pd.get_dummies(df2.visible_ice)\n",
    "# bin_visible_ice = (~visible_ice['No visible ice'].astype('bool')).astype('int')\n",
    "# bin_visible_ice.value_counts()\n",
    "\n",
    "# df2['visible_ice'] = bin_visible_ice\n",
    "\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1837f5df-ee84-4d0d-9942-14b948a37934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.dropna(subset=['materials'])\n",
    "df3['materials'].replace(['ICE'], 'Ice', regex=True, inplace=True)\n",
    "df3['materials'].replace(['ice'], 'Ice', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dba8d5fb-1a64-4fea-a69a-20b744e097a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_materials = pd.get_dummies(df3.materials)\n",
    "df3['material_ice'] = dm_materials['Ice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32ecd3dc-6e04-48d5-84b0-6b3ce4251644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = pd.read_csv(r\"C:\\Users\\mouju\\Desktop\\film\\components_analysis\\df_unique.csv\", header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75c3c456-b700-46cd-9a6d-52872ba14aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Geo90Dataset(Dataset):\n",
    "    def __init__(self, data_root, df, base_lat, base_lng, chip_size=32):\n",
    "        \n",
    "        self.base_lat = base_lat\n",
    "        self.base_lng = base_lng\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        self.chip_size = chip_size\n",
    "        \n",
    "        self.trans = transforms.ToTensor()\n",
    "        \n",
    "        self.n_channels = len(os.listdir(data_root))\n",
    "        self.preloaded = torch.ones(self.n_channels, 6000, 6000)\n",
    "        \n",
    "        for i, file in enumerate(os.listdir(data_root)):\n",
    "            # name = file.split('_')[0]\n",
    "            # print(name)\n",
    "            \n",
    "            I = np.array(Image.open(data_root + os.path.sep + file))\n",
    "            print(I.shape)\n",
    "            # I = plt.imread(data_root + os.path.sep + file)\n",
    "            \n",
    "#             print(I.max())\n",
    "#             print(I.min())\n",
    "            \n",
    "#             # normalize\n",
    "#             I = (((I - I.min()) / (I.max() - I.min())) * 255.9).astype(np.uint8)\n",
    "#             print(I.max())\n",
    "#             print(I.min())\n",
    "            \n",
    "            self.preloaded[i] = self.trans(I)\n",
    "            \n",
    "        \n",
    "        \n",
    "        print('Dataset initialized')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        bh_id = row.at['borehole']\n",
    "        lat = row.at['latitude']\n",
    "        lng = row.at['longitude']\n",
    "        \n",
    "\n",
    "        pixel_len = 5/6000\n",
    "        \n",
    "\n",
    "        lat_index_start = np.round((self.base_lat - lat) / pixel_len - self.chip_size/2).astype(int)\n",
    "        lat_index_end = lat_index_start + self.chip_size\n",
    "        \n",
    "        lng_index_start = np.round((lng - self.base_lng) / pixel_len - self.chip_size/2).astype(int)\n",
    "        lng_index_end = lng_index_start + self.chip_size\n",
    "        \n",
    "        image = self.preloaded[:, lat_index_start:lat_index_end,lng_index_start:lng_index_end]\n",
    "        \n",
    "        \n",
    "        # surface = torch.tensor(row.filter(['depth'])).float()\n",
    "        surface = torch.tensor(row.filter(['depth_norm', 'month_cyclic_norm', 'lat_norm', 'lng_norm', 'year_norm'])).float()\n",
    "        \n",
    "        frozen = torch.tensor(row.at['frozen']).float()\n",
    "        \n",
    "        # visible_ice = torch.tensor(row.at['visible_ice']).float()\n",
    "        visible_ice = torch.tensor(row.at['visible_ice_code']).long()\n",
    "        \n",
    "        # material_ice = torch.tensor(row.at['material_ice']).float()\n",
    "        \n",
    "        return {'image': image, 'surface_data': surface, 'frozen': frozen,  'visible_ice': visible_ice} #'material_ice': material_ice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d26ba2b-3c00-436f-a175-933f8b97eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "(6000, 6000)\n",
      "Dataset initialized\n",
      "(6000, 6000)\n",
      "Dataset initialized\n"
     ]
    }
   ],
   "source": [
    "base_lat = 70\n",
    "base_lng = -135\n",
    "\n",
    "loaded_dataset = Geo90Dataset(data_root, df2, base_lat, base_lng, chip_size)\n",
    "test_dataset = Geo90Dataset(\"geomorph_data_test\", df_unique, base_lat, base_lng, chip_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "153cc6da-674e-4a77-b3ca-1324682c7ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0]['image'].shape)\n",
    "\n",
    "chips_root = \"geomorph_data_test_chips\"\n",
    "\n",
    "for i, data in enumerate(test_dataset):\n",
    "    \n",
    "    save_image(data['image'], os.path.join(\"geomorph_data_test_chips\", f'{i:04d}.png'))\n",
    "    # np.save(os.path.join(chips_root, f'{i:04d}.npy'), data['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b0df9-d51d-4bb3-9658-7a49e95bc6a6",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f46b0-7537-4ceb-8f96-263c007e97fd",
   "metadata": {},
   "source": [
    "## FiLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "214c4911-bcfb-43a2-b41b-b01949690b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_film_params = hidden_width * hidden_nblocks * 2\n",
    "\n",
    "# generator = resnet18(n_channels, n_film_params)\n",
    "\n",
    "def train_model(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    # loss: binary cross entropy\n",
    "\n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    # print(gen_model)\n",
    "\n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    net_model = mlp(input_size[0],output_size, hidden_width, hidden_nblocks).to(device)\n",
    "    \n",
    "    gen_optimizer = torch.optim.Adam(gen_model.parameters(), weight_decay = L2_param)\n",
    "    net_optimizer = torch.optim.Adam(net_model.parameters(), weight_decay = L2_param)\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "\n",
    "    # --------- check back propagation ----------- -\n",
    "    # net_model.fc1.weight.register_hook(lambda x: print('grad accumulated in mlp fc1'))\n",
    "    # gen_first_layer = gen_model.encoder.blocks[0].blocks[0].blocks[0].conv\n",
    "    # gen_first_layer.weight.register_hook(lambda x: print('grad accumulated in resnet first layer'))\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        # ------------ train -----------------\n",
    "        gen_model.train()\n",
    "        net_model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            \n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            net_optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            gen_optimizer.step()\n",
    "            net_optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        gen_model.eval()\n",
    "        net_model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # TODO: exammine film_params gradients / readup pytorch\n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "\n",
    "        torch.save(gen_model.state_dict(), os.path.join('mlp-resnet-models/', 'gen-epoch-{}.pt'.format(epoch+1)))\n",
    "        torch.save(net_model.state_dict(), os.path.join('mlp-resnet-models/', 'net-epoch-{}.pt'.format(epoch+1)))\n",
    "\n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "## Test model\n",
    "\n",
    "def test_model(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    net_model = mlp(input_size[0], output_size, hidden_width, hidden_nblocks)\n",
    "\n",
    "    gen_model.load_state_dict(torch.load('mlp-resnet-models/gen-epoch-{}.pt'.format(ind+1)))\n",
    "    net_model.load_state_dict(torch.load('mlp-resnet-models/net-epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    gen_model.eval()\n",
    "    net_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, surface_data, labels = data['image'].to(device), data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(surface_data, gen_params)\n",
    "            \n",
    "            output = sm(predicted)\n",
    "            # print(output)\n",
    "            \n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "            #predicted = torch.round(output)\n",
    "            # print(predicted.shape)\n",
    "            \n",
    "            y_test.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            \n",
    "#             predicted = torch.squeeze(predicted)\n",
    "\n",
    "#             predicted = torch.round(predicted)\n",
    "#             # print(predicted.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             lb = labels.tolist()\n",
    "#             pr = predicted.tolist()\n",
    "#             y_test.extend(lb)\n",
    "#             y_pred.extend(pr)\n",
    "    \n",
    "    arr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
    "    return arr_accuracy, scores, gen_model, net_model\n",
    "\n",
    "\n",
    "#     print(confusion_matrix(y_test,y_pred))\n",
    "#     print(classification_report(y_test,y_pred))\n",
    "#     print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "## Pure MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8b5b0-1039-4c76-93e4-0f90b60d87be",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43c02928-f9c5-4b2a-8ef7-d8a2de4a4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_pure(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(mlp_pure, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_size = hidden_width\n",
    "            self.hidden_nblocks = hidden_nblocks\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size,self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.end = torch.nn.Softmax(dim=-1) ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            # print(out.shape)\n",
    "            \n",
    "            for i in range(self.hidden_nblocks):\n",
    "                out = self.fc2(out)\n",
    "                out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            # out = self.end(out)\n",
    "            return out\n",
    "\n",
    "def train_mlp(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    surface_model = mlp_pure(input_size[0],output_size)\n",
    "    \n",
    "    surface_model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(surface_model.parameters(), weight_decay = L2_param)\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        surface_model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            surface_data, labels = data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            predicted = surface_model(surface_data)\n",
    "            \n",
    "#             print(predicted.squeeze().shape)\n",
    "#             print(labels.shape)\n",
    "            \n",
    "            \n",
    "            # squeeze: return tensor with all dimensions of size 1 removed\n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        surface_model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            surface_data, labels = data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            predicted = surface_model(surface_data)\n",
    "            \n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "\n",
    "        torch.save(surface_model.state_dict(), os.path.join('mlp-models/', 'epoch-{}.pt'.format(epoch+1)))\n",
    "    \n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "        \n",
    "    return epoch_loss\n",
    "        \n",
    "def test_mlp(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    input_size = list(full_dataset[0]['surface_data'].size())\n",
    "    \n",
    "    surface_model = mlp_pure(input_size[0],output_size)\n",
    "    surface_model.load_state_dict(torch.load('mlp-models/epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    surface_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    surface_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        y_cert = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            surface_data, labels = data['surface_data'].to(device), data[label_name].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            output = surface_model(surface_data)\n",
    "            \n",
    "            output = sm(output)\n",
    "            # print(output)\n",
    "            \n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "            certainty = max_results.values\n",
    "            #predicted = torch.round(output)\n",
    "            # print(predicted.shape)\n",
    "            \n",
    "            y_test.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            y_cert.extend(certainty.tolist())\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "#     print(y_test)\n",
    "#     print(y_pred)\n",
    "    with open(\"mlp-certainty/iteration_{}.txt\".format(it), \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(y_cert, fp)\n",
    "    #with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "        #b = pickle.load(fp)\n",
    "    arr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
    "    return arr_accuracy, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cfb6b-c5ca-4fdd-81e9-571685a86522",
   "metadata": {},
   "source": [
    "## Multiple Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44629f3-5888-4eb0-8f54-cfd63f455c54",
   "metadata": {},
   "source": [
    "### Discard samples with invalid values in image chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc861435-97ab-4095-9760-4b797477daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2752\n",
      "2717\n"
     ]
    }
   ],
   "source": [
    "valid_ind = []\n",
    "for i, data in enumerate(loaded_dataset):\n",
    "    image = data['image']\n",
    "    ind  = (image == -9999)\n",
    "    if ~torch.any(ind):\n",
    "        valid_ind.append(i)\n",
    "\n",
    "full_dataset = torch.utils.data.Subset(loaded_dataset, valid_ind)\n",
    "\n",
    "\n",
    "print(len(loaded_dataset))\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba299154-57ac-4e30-bf2e-74e41e3fc64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "# batchsize can cause error when last leftover batchsize is 1, batchnorm cannot function on 1 sample data\n",
    "batchsize = 20\n",
    "while(train_size % batchsize == 1):\n",
    "    batchsize+=1\n",
    "print(batchsize)\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb6971-4f9e-409e-b8ee-9ebe27a3cfae",
   "metadata": {},
   "source": [
    "## Scale of image chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e37318c4-ff02-48e0-aa8c-c5a708eb0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = full_dataset[0]['image']\n",
    "# n_samples = len(train_data)\n",
    "# n_channels = list(image.shape)[0]\n",
    "\n",
    "# scalers = []\n",
    "# for i in range(n_channels):\n",
    "#     print(i)\n",
    "#     scaler = StandardScaler()\n",
    "#     X = torch.empty((n_samples, chip_size, chip_size))\n",
    "    \n",
    "#     for j, data in enumerate(train_data):\n",
    "#         #print(data['image'][i].shape)\n",
    "#         # print(X[j].shape)\n",
    "#         X[j] = data['image'][i]\n",
    "#     X = torch.reshape(X, (-1,1))\n",
    "#     #print(X)\n",
    "#     # break;\n",
    "#     scaler.fit(X)\n",
    "#     scalers.append(scaler)\n",
    "    \n",
    "#     def scale_data(subset):\n",
    "#         for data in subset:\n",
    "#             X = data['image'][i]\n",
    "#             X_flat = torch.reshape(X, (-1,1))\n",
    "            \n",
    "#             X_trans = scaler.transform(X_flat)\n",
    "#             data['image'][i] = torch.reshape(torch.Tensor(X_trans), (chip_size, chip_size))\n",
    "    \n",
    "#     scale_data(train_data)\n",
    "#     scale_data(test_data)\n",
    "#     print(\"Channel {} scaled.\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f7a6d03-a8b0-4c0f-b562-415f30deb0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1: running loss: 1.45615, validation loss: 1.34795\n",
      "epoch  2: running loss: 1.39012, validation loss: 1.35755\n",
      "epoch  3: running loss: 1.36648, validation loss: 1.39185\n",
      "epoch  4: running loss: 1.37213, validation loss: 1.34030\n",
      "epoch  5: running loss: 1.34600, validation loss: 1.32569\n",
      "epoch  6: running loss: 1.34572, validation loss: 1.32880\n",
      "epoch  7: running loss: 1.33069, validation loss: 1.33198\n",
      "epoch  8: running loss: 1.32373, validation loss: 1.31909\n",
      "epoch  9: running loss: 1.30282, validation loss: 1.33464\n",
      "epoch 10: running loss: 1.30822, validation loss: 1.33000\n",
      "epoch 11: running loss: 1.30470, validation loss: 1.31489\n",
      "epoch 12: running loss: 1.28403, validation loss: 1.32786\n",
      "epoch 13: running loss: 1.28446, validation loss: 1.35294\n",
      "epoch 14: running loss: 1.27631, validation loss: 1.32534\n",
      "epoch 15: running loss: 1.25743, validation loss: 1.34022\n",
      "epoch 16: running loss: 1.25305, validation loss: 1.31867\n",
      "epoch 17: running loss: 1.24354, validation loss: 1.35726\n",
      "epoch 18: running loss: 1.22482, validation loss: 1.33959\n",
      "epoch 19: running loss: 1.23297, validation loss: 1.39938\n",
      "epoch 20: running loss: 1.23884, validation loss: 1.45726\n",
      "epoch 21: running loss: 1.35332, validation loss: 1.33565\n",
      "epoch 22: running loss: 1.27541, validation loss: 1.31287\n",
      "epoch 23: running loss: 1.24781, validation loss: 1.33174\n",
      "epoch 24: running loss: 1.22285, validation loss: 1.31670\n",
      "epoch 25: running loss: 1.20062, validation loss: 1.33654\n",
      "epoch 26: running loss: 1.19727, validation loss: 1.32827\n",
      "epoch 27: running loss: 1.17665, validation loss: 1.35038\n",
      "epoch 28: running loss: 1.17979, validation loss: 1.34101\n",
      "epoch 29: running loss: 1.17117, validation loss: 1.33238\n",
      "epoch 30: running loss: 1.17529, validation loss: 1.31774\n",
      "epoch 31: running loss: 1.15209, validation loss: 1.39002\n",
      "epoch 32: running loss: 1.15865, validation loss: 1.33879\n",
      "epoch 33: running loss: 1.14208, validation loss: 1.35569\n",
      "epoch 34: running loss: 1.13286, validation loss: 1.37428\n",
      "epoch 35: running loss: 1.13258, validation loss: 1.37475\n",
      "epoch 36: running loss: 1.12551, validation loss: 1.39555\n",
      "epoch 37: running loss: 1.11567, validation loss: 1.35878\n",
      "epoch 38: running loss: 1.11288, validation loss: 1.40900\n",
      "epoch 39: running loss: 1.09813, validation loss: 1.36780\n",
      "epoch 40: running loss: 1.09539, validation loss: 1.42158\n",
      "epoch 41: running loss: 1.09615, validation loss: 1.39697\n",
      "epoch 42: running loss: 1.10749, validation loss: 1.38785\n",
      "epoch 43: running loss: 1.09104, validation loss: 1.40093\n",
      "epoch 44: running loss: 1.07694, validation loss: 1.43937\n",
      "epoch 45: running loss: 1.06674, validation loss: 1.37136\n",
      "epoch 46: running loss: 1.07277, validation loss: 1.39063\n",
      "epoch 47: running loss: 1.05698, validation loss: 1.46397\n",
      "epoch 48: running loss: 1.05551, validation loss: 1.48095\n",
      "epoch 49: running loss: 1.06396, validation loss: 1.47941\n",
      "epoch 50: running loss: 1.05108, validation loss: 1.49621\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for mlp:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([5, 32]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-8d0ec301cd83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#     # ------- mlp-resnet film\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_model_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# scores = precision, recall, fscore, support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-db5a6461a75c>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(epoch_loss, print_model_epoch)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mgen_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mlp-resnet-models/gen-epoch-{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mnet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mlp-resnet-models/net-epoch-{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mgen_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1408\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for mlp:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([5, 32]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "max_iterations = 1\n",
    "results = np.zeros([max_iterations, num_classes*4 + 1])\n",
    "# trainloader, testloader = prepare_dataloader(full_dataset)\n",
    "\n",
    "for it in range(max_iterations):\n",
    "    start = time.time()\n",
    "    \n",
    "    # mlp\n",
    "#     epoch_loss_mlp = train_mlp(trainloader,testloader, print_epochs = True, loss_fn = nn.CrossEntropyLoss())\n",
    "#     acc, scores = test_mlp(epoch_loss_mlp, print_model_epoch = True)\n",
    "    \n",
    "    #     # ------- mlp-resnet film \n",
    "    epoch_loss = train_model(trainloader, testloader, print_epochs=True, loss_fn = nn.CrossEntropyLoss())\n",
    "    acc, scores, gen_model, net_model = test_model(epoch_loss, print_model_epoch = True)\n",
    "    \n",
    "    # scores = precision, recall, fscore, support\n",
    "    results[it, 0] = acc\n",
    "    \n",
    "    for j, score in enumerate(scores):\n",
    "        start_ind = 1 + j*num_classes\n",
    "        results[it, start_ind: start_ind + num_classes] = score\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print('iteration {} elapsed time: {}, accuracy : {}'.format(it+1, end-start, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c5555c3-2ed2-4e85-9c9b-0c3985f51881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 model selected\n"
     ]
    }
   ],
   "source": [
    "acc, scores, gen_model, net_model = test_model(epoch_loss, print_model_epoch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a2433-e48a-459f-bc98-a1d16f330f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(scores):\n",
    "    df = np.reshape(scores, [num_classes,4], order ='F')\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    # df.style.set_table_attributes(\"style='display:inline'\").set_caption(mode)\n",
    "    \n",
    "    df.columns = ['precision', 'recall', 'f1', 'support']\n",
    "    # df.index = ['unfrozen', 'frozen']\n",
    "    # df.index = ['Visible ice', 'No visible ice']\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "def display_results(results):\n",
    "    mean = np.mean(results, axis=0)\n",
    "    std = np.std(results, axis=0)\n",
    "    \n",
    "    print(\"mean\")\n",
    "    display_table(mean[1:])\n",
    "    \n",
    "    print(\"std\")\n",
    "    display_table(std[1:])\n",
    "    \n",
    "    print(\"Accuracy mean: {}, std: {}\".format(mean[0], std[0]))\n",
    "\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360fa50-304f-4e3b-b33a-51b9f820a580",
   "metadata": {},
   "source": [
    "## Display Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b51afa27-1fb7-4bf4-9da2-82b90a263657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df.depth.max())\n",
    "print(df.depth.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b8c1174-a942-4f78-8a9f-4d1bb0f8b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_max = 69.5\n",
    "latitude_min = 68.3\n",
    "longitude_max = -132.8\n",
    "longitude_min = -133.9\n",
    "\n",
    "n_lat = 40\n",
    "n_lng = 20\n",
    "\n",
    "\n",
    "lng_range = np.linspace(longitude_min, longitude_max, n_lng)\n",
    "lat_range = np.linspace(latitude_min, latitude_max, n_lat)\n",
    "depth_range = [1, 3, 5, 7, 9]\n",
    "n_depth = len(depth_range)\n",
    "\n",
    "grid_lng, grid_lat, grid_depth = np.meshgrid(lng_range, lat_range, depth_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "946bd4b9-c52f-4c0c-aec0-db5dd6176c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = pd.DataFrame(columns=['latitude', 'longitude', 'depth', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9d4dce3-206c-4862-b6b9-18bf06583869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn['latitude'] = grid_lat.flatten()\n",
    "df_syn['longitude'] = grid_lng.flatten()\n",
    "df_syn['depth'] = grid_depth.flatten()\n",
    "df_syn['year'] = 2013\n",
    "df_syn['month'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5aa90869-47cc-481f-b33e-e28f1bcb17ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>69.5</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>69.5</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>69.5</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>69.5</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>69.5</td>\n",
       "      <td>-132.8</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude  depth  year  month\n",
       "3995      69.5     -132.8      1  2013      3\n",
       "3996      69.5     -132.8      3  2013      3\n",
       "3997      69.5     -132.8      5  2013      3\n",
       "3998      69.5     -132.8      7  2013      3\n",
       "3999      69.5     -132.8      9  2013      3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca2e1789-890d-45cd-86a4-9cc1b2124194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  68.77996824, -133.50176278,    3.95760839, 2013.37715897,\n",
       "          3.62460345])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceb5256c-18c4-429c-b4d5-947a845e9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = scaler.transform(df_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "213f1a29-7853-43c9-af0b-b3fccfe40351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.81088706, -1.77691568, -0.79555272, -0.31905326, -1.22529482],\n",
       "       [-1.81088706, -1.77691568, -0.25758243, -0.31905326, -1.22529482],\n",
       "       [-1.81088706, -1.77691568,  0.28038786, -0.31905326, -1.22529482],\n",
       "       ...,\n",
       "       [ 2.71663018,  3.13123246,  0.28038786, -0.31905326, -1.22529482],\n",
       "       [ 2.71663018,  3.13123246,  0.81835815, -0.31905326, -1.22529482],\n",
       "       [ 2.71663018,  3.13123246,  1.35632844, -0.31905326, -1.22529482]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "272aaf1a-afbb-4a68-b560-b80f30a2d280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8359, -1.2253,  1.4399,  1.8515, -1.1650])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[0]['surface_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56c8a0d6-6de8-4fce-b995-099c3d73f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 model selected\n"
     ]
    }
   ],
   "source": [
    "# ------ select model ---------\n",
    "ind = 40\n",
    "\n",
    "input_size = list(full_dataset[0]['surface_data'].size())\n",
    "\n",
    "surface_model = mlp_pure(input_size[0],output_size)\n",
    "\n",
    "surface_model.load_state_dict(torch.load('mlp-models/epoch-{}.pt'.format(ind+1)))\n",
    "\n",
    "surface_model.to(device)\n",
    "\n",
    "# surface_model = surface_model.float()\n",
    "\n",
    "print(\"epoch {} model selected\".format(ind+1))\n",
    "\n",
    "# evaluate model on synthetic set\n",
    "surface_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    y_cert = []\n",
    "    \n",
    "    surface_data= torch.from_numpy(df_syn).float().to(device)\n",
    "\n",
    "    # y_test.append(label.numpy().list())\n",
    "    # print(label.shape)\n",
    "    # print(images.shape)\n",
    "\n",
    "    output = surface_model(surface_data)\n",
    "\n",
    "    output = sm(output)\n",
    "    # print(output)\n",
    "    \n",
    "    # proxy for uncertainty\n",
    "    # cross entropy penalizes value for not being close to 1 when it's the right category\n",
    "    # saturate leading to overconfidence\n",
    "\n",
    "    max_results = torch.max(output, dim= -1)\n",
    "    predicted = max_results.indices\n",
    "    certainty = max_results.values\n",
    "\n",
    "predicted = predicted.reshape(n_lng, n_lat, n_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b5a81c7-c31d-4bcf-b11a-09021028a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reshaped = predicted.reshape(n_lng, n_lat, n_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d3deb01-0c75-4e46-8acb-78dcbdf67035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 40, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1da8f0d-d3d2-4bfd-ab92-e0fb060fea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b3492c4670>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predicted[:, :, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84f41e-6256-4ef3-9664-a4ff26c867b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "385e80c1-699d-4e37-9153-57629f56614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2d = torch.sum(predicted, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd48bfd7-9ea2-484e-b418-f5db6f7493de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b35290eb50>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predicted_2d.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72896a9a-2a6c-4e8d-a78b-474415d64182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.colors import to_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14b09b6a-96e3-4b97-81dd-2101e9710289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmplot as gp\n",
    "\n",
    "mean_lat = df2.latitude.unique().mean()\n",
    "mean_lng = df2.longitude.unique().mean()\n",
    "\n",
    "grid_lng_2d, grid_lat_2d = np.meshgrid(lng_range, lat_range)\n",
    "grid_lng_2d = grid_lng_2d.flatten()\n",
    "grid_lat_2d = grid_lat_2d.flatten()\n",
    "\n",
    "grid_lat_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec7f4bfd-1b83-4774-8fa0-83f9dc978cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocean = cm.get_cmap('inferno',predicted_2d.max())\n",
    "\n",
    "predicted_2d = predicted_2d.flatten().cpu()\n",
    "color_ice = ocean(predicted_2d)\n",
    "len(color_ice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26bb1487-24e0-446b-b27d-538c47df6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_ice_hex = [None] * len(color_ice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb11ca0e-2622-4ecd-b16c-fe88d3e76d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color in enumerate(color_ice):\n",
    "    color_ice_hex[i] = to_hex(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ce4699c-01e9-44cb-bfb8-550c21f75ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gp.GoogleMapPlotter(mean_lat, mean_lng, 8, apikey = \"AIzaSyBUVgOpJ5OP6L3Rsmtbzy1cTCegpyPAvF4\")\n",
    "# use \"maps javascript api\" credential\n",
    " \n",
    "gmap.scatter(grid_lat_2d, grid_lng_2d, s = 1000, c=color_ice_hex, marker=False) #, color='#3B0B39', size=40, marker=False)\n",
    "# gmap.heatmap(df2.latitude.tolist(), df2.longitude.tolist())  \n",
    "\n",
    "# gmap.scatter(grid_lat_2d[0:2], grid_lng_2d[0:2], s = 500, c=ocean[predicted_2d[0:2]])\n",
    "\n",
    "# Pass the absolute path\n",
    "now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "gmap.draw( \"map_ice{}.html\".format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866904e-fdc6-4889-9fb9-4af653fc9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lng_2d.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bdff7-6416-4068-b906-d31f96171af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2d.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576ea58-15e5-4c76-84a5-b42c4417e5d2",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "574ef1cb-9cad-4a3f-81db-c965767e1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f2d978c-5c1a-49e6-8c5a-1378c59c44da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ac0ea32-d485-40ab-a987-8a2b125e6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_surfaces = batch['surface_data'].to('cpu')\n",
    "test_images = batch['image'].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff96d72b-73c4-47bf-b185-8fea58f0211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d0a2b5b5-310a-49e3-bd70-eedba4516be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "455979e9-a7f0-4ad3-afd4-c01e4d8dfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_surfaces = batch['surface_data'].to('cpu')\n",
    "train_images = batch['image'].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "179e5115-c73b-4e0d-aa42-bc844a104626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp(\n",
       "  (fc1): Linear(in_features=5, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (end): Softmax(dim=-1)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.to('cpu')\n",
    "net_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7465cc90-ce11-4650-83c2-3a35701bb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85e6e263-097d-4b37-b5e1-48d6f194baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_gen = shap.DeepExplainer(gen_model, train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c62be1c9-df0d-49a7-bbe4-ba332ecca1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6451a262-d427-4593-a542-a4a6d1f5f40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 25, 32, 32])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ab35a51-7dbe-4a19-be50-d6e41cc2c260",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): Tensors must have same number of dimensions: got 4 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-c68d6304d8ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;34m\"top\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \"\"\"\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    180\u001b[0m                                    (self.data[l].shape[0],) + tuple([1 for k in range(len(X[l].shape) - 1)])) for l\n\u001b[0;32m    181\u001b[0m                            in range(len(X))]\n\u001b[1;32m--> 182\u001b[1;33m                 \u001b[0mjoint_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtiled_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m                 \u001b[1;31m# run attribution computation graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    180\u001b[0m                                    (self.data[l].shape[0],) + tuple([1 for k in range(len(X[l].shape) - 1)])) for l\n\u001b[0;32m    181\u001b[0m                            in range(len(X))]\n\u001b[1;32m--> 182\u001b[1;33m                 \u001b[0mjoint_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtiled_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m                 \u001b[1;31m# run attribution computation graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): Tensors must have same number of dimensions: got 4 and 2"
     ]
    }
   ],
   "source": [
    "shap_values = e.shap_values(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b377abe3-9360-452c-aafa-4916acaa02e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a3a54-0c13-4251-a62c-8d20a6d750d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
