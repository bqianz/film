{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6226f91b-b132-462a-830e-fea5799d147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5b14da-a3b5-41b8-95e0-ff0c4c9585a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_width = 32\n",
    "hidden_nblocks = 4\n",
    "train_max_epoch = 30\n",
    "max_iterations = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "L2_param = 1e-5\n",
    "\n",
    "label_name = \"visible_ice\"\n",
    "num_classes = 10\n",
    "output_size = 10\n",
    "\n",
    "sm = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1681aae5-8588-4006-9718-0bab501950fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f153a451-f23f-4365-aa25-df6b603283cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4443576b-6821-4bbd-95fa-dd2fed2bf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows = trainX.shape[0]\n",
    "random_indices = np.random.choice(number_of_rows, size=number_of_rows//100, replace=False)\n",
    "trainX = trainX[random_indices]\n",
    "trainY = trainY[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593b7a2d-c769-49d4-a7a0-a4198fe580f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbf378b-9749-453c-8325-33d61ce2054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10_Dataset(Dataset):\n",
    "    def __init__(self, image_data, labels):\n",
    "        \n",
    "        \n",
    "        self.tabular_data = np.empty([labels.shape[0], 5])\n",
    "        self.image_data = image_data\n",
    "        self.labels = labels\n",
    "        # cargo capacity, number of legs, number of wheels, organic, water\n",
    "        for i, label in enumerate(labels):\n",
    "            if label[0] == 0: # airplane\n",
    "                self.tabular_data[i] = [1000, 0, 10, 0, 0]\n",
    "            elif label[0] == 1: # automobile\n",
    "                self.tabular_data[i] = [200, 0, 4, 0, 0]\n",
    "            elif label[0] == 2: # bird\n",
    "                self.tabular_data[i] = [0, 2, 0, 1, 0]\n",
    "            elif label[0] == 3: # cat\n",
    "                self.tabular_data[i] = [0, 4, 0, 1, 0]\n",
    "            elif label[0] == 4: # deer\n",
    "                self.tabular_data[i] = [0, 4, 0, 1, 0]\n",
    "            elif label[0] == 5: # dog\n",
    "                self.tabular_data[i] = [0, 4, 0, 1, 1]\n",
    "            elif label[0] == 6: # frog\n",
    "                self.tabular_data[i] = [0, 4, 0, 1, 1]\n",
    "            elif label[0] == 7: #horse\n",
    "                self.tabular_data[i] = [100, 4, 0, 1, 0]\n",
    "            elif label[0] == 8: # ship\n",
    "                self.tabular_data[i] = [5000, 0, 0, 0, 1]\n",
    "            elif label[0] == 9: #truck\n",
    "                self.tabular_data[i] = [500, 0, 4, 0, 0]\n",
    "        \n",
    "        print('Dataset initialized')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.image_data[idx]).float()\n",
    "        image = torch.permute(image, (2,0,1))\n",
    "        \n",
    "        return {'tabular': torch.tensor(self.tabular_data[idx]).float(),'image': image,'label': torch.tensor(self.labels[idx][0]).long()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adf9fe5-05cb-480f-bae1-dcb9964c4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized\n",
      "Dataset initialized\n"
     ]
    }
   ],
   "source": [
    "train_dataset = cifar10_Dataset(trainX, trainY)\n",
    "test_dataset = cifar10_Dataset(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed15443c-8e95-48c4-80ad-e6c99ca2a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.8 * len(full_dataset))\n",
    "# test_size = len(full_dataset) - train_size\n",
    "\n",
    "# batchsize can cause error when last leftover batchsize is 1, batchnorm cannot function on 1 sample data\n",
    "batchsize = 20\n",
    "# while(train_size % batchsize == 1):\n",
    "#     batchsize+=1\n",
    "# print(batchsize)\n",
    "\n",
    "# train_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db0099-cf78-493d-bbe2-7b4958fc2ff3",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fafcb32-cd38-4385-85d4-8669c9d2579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_pure(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(mlp_pure, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_size = hidden_width\n",
    "            self.hidden_nblocks = hidden_nblocks\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size,self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.end = torch.nn.Softmax(dim=-1) ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            # print(out.shape)\n",
    "            \n",
    "            for i in range(self.hidden_nblocks):\n",
    "                out = self.fc2(out)\n",
    "                out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            # out = self.end(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993234c7-0d47-43b2-9ea1-38b100a2fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    \n",
    "    input_size = list(train_dataset[0]['tabular'].size())\n",
    "    \n",
    "    mlp_model = mlp_pure(input_size[0],output_size)\n",
    "    mlp_model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(mlp_model.parameters(), weight_decay = L2_param)\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    \n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        mlp_model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            tabular_data, labels = data['tabular'].to(device), data['label'].to(device)\n",
    "\n",
    "            predicted = mlp_model(tabular_data)\n",
    "            \n",
    "            # print(predicted.shape)\n",
    "            \n",
    "            # squeeze: return tensor with all dimensions of size 1 removed\n",
    "#             print(predicted.squeeze().shape)\n",
    "#             print(labels.shape)\n",
    "            \n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        mlp_model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            tabular_data, labels = data['tabular'].to(device), data['label'].to(device)\n",
    "            predicted = mlp_model(tabular_data)\n",
    "            \n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "\n",
    "        torch.save(mlp_model.state_dict(), os.path.join('mlp_test_models/', 'epoch-{}.pt'.format(epoch+1)))\n",
    "    \n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "        \n",
    "    return epoch_loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "177ce011-4c90-43da-b0c4-9b5f73630752",
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def test_mlp(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    input_size = list(train_dataset[0]['tabular'].size())\n",
    "    \n",
    "    mlp_model = mlp_pure(input_size[0],output_size)\n",
    "    mlp_model.load_state_dict(torch.load('mlp_test_models/epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    mlp_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    mlp_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        y_cert = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            tabular_data, labels = data['tabular'].to(device), data['label'].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            output = mlp_model(tabular_data)\n",
    "            \n",
    "            output = sm(output)\n",
    "            # print(output)\n",
    "            \n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "            certainty = max_results.values\n",
    "            #predicted = torch.round(output)\n",
    "            # print(predicted.shape)\n",
    "            \n",
    "            y_test.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            y_cert.extend(certainty.tolist())\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "#     print(y_test)\n",
    "#     print(y_pred)\n",
    "#     with open(\"mlp-certainty/iteration_{}.txt\".format(it), \"wb\") as fp:   #Pickling\n",
    "#         pickle.dump(y_cert, fp)\n",
    "    #with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "        #b = pickle.load(fp)\n",
    "    \n",
    "    arr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
    "    return arr_accuracy, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa2764-0126-4a41-949b-e0ca07ec26d0",
   "metadata": {},
   "source": [
    "## film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01c9402-50f7-4053-ba99-badfa265bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "        def __init__(self, input_size, output_size = 1, hidden_width = 20, hidden_nblocks = 2):\n",
    "            super(mlp, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_width = hidden_width\n",
    "            self.hidden_nblocks = hidden_nblocks\n",
    "            \n",
    "            self.fc1 = nn.Linear(self.input_size, self.hidden_width)\n",
    "            self.fc2 = nn.Linear(self.hidden_width,self.hidden_width)\n",
    "            self.fc3 = nn.Linear(self.hidden_width, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.end= torch.nn.Softmax(dim = -1) ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "            self.dropout = nn.Dropout(0.25)\n",
    "            \n",
    "        def forward(self, x, film_params):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            \n",
    "            for i in range(self.hidden_nblocks):\n",
    "                out = self.fc2(out)\n",
    "                \n",
    "                # ------- film layer -----------\n",
    "                start = i * hidden_width * 2\n",
    "                mid = start + hidden_width\n",
    "                end = mid + hidden_width\n",
    "                \n",
    "                gamma = film_params[:, start : mid]\n",
    "                beta = film_params[:, mid : end]\n",
    "                \n",
    "#                 print(out.shape)\n",
    "#                 print(gamma.shape)\n",
    "#                 print(beta.shape)\n",
    "                \n",
    "                out = out * gamma\n",
    "                out += beta\n",
    "                # ------- film layer -----------\n",
    "                # out = self.dropout(out)\n",
    "                out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            # out = self.end(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b47773f-56c4-4cb7-93f4-cda6472cd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_film_params = hidden_width * hidden_nblocks * 2\n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "def train_model(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    # loss: binary cross entropy\n",
    "\n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    # print(gen_model)\n",
    "\n",
    "    input_size = list(train_dataset[0]['tabular'].size())\n",
    "    net_model = mlp(input_size[0], output_size, hidden_width, hidden_nblocks).to(device)\n",
    "    \n",
    "    gen_optimizer = torch.optim.Adam(gen_model.parameters(), weight_decay = L2_param)\n",
    "    net_optimizer = torch.optim.Adam(net_model.parameters(), weight_decay = L2_param)\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "\n",
    "    # --------- check back propagation ----------- -\n",
    "    # net_model.fc1.weight.register_hook(lambda x: print('grad accumulated in mlp fc1'))\n",
    "    # gen_first_layer = gen_model.encoder.blocks[0].blocks[0].blocks[0].conv\n",
    "    # gen_first_layer.weight.register_hook(lambda x: print('grad accumulated in resnet first layer'))\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    \n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        # ------------ train -----------------\n",
    "        gen_model.train()\n",
    "        net_model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, tabular_data, labels = data['image'].to(device), data['tabular'].to(device), data['label'].to(device)\n",
    "\n",
    "            \n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(tabular_data, gen_params)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            net_optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            gen_optimizer.step()\n",
    "            net_optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        gen_model.eval()\n",
    "        net_model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, tabular_data, labels = data['image'].to(device), data['tabular'].to(device), data['label'].to(device)\n",
    "\n",
    "            # TODO: exammine film_params gradients / readup pytorch\n",
    "            gen_params = gen_model(images)\n",
    "            predicted = net_model(tabular_data, gen_params)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "\n",
    "        torch.save(gen_model.state_dict(), os.path.join('film_test_models/', 'gen-epoch-{}.pt'.format(epoch+1)))\n",
    "        torch.save(net_model.state_dict(), os.path.join('film_test_models/', 'net-epoch-{}.pt'.format(epoch+1)))\n",
    "\n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "## Test model\n",
    "\n",
    "def test_model(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    generator = models.resnet18()\n",
    "    generator.fc = nn.Linear(512, n_film_params)\n",
    "    generator.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    \n",
    "    gen_model = generator\n",
    "\n",
    "    input_size = list(train_dataset[0]['tabular'].size())\n",
    "    net_model = mlp(input_size[0], output_size, hidden_width, hidden_nblocks)\n",
    "\n",
    "    gen_model.load_state_dict(torch.load('film_test_models/gen-epoch-{}.pt'.format(ind+1)))\n",
    "    net_model.load_state_dict(torch.load('film_test_models/net-epoch-{}.pt'.format(ind+1)))\n",
    "    \n",
    "    gen_model.to(device)\n",
    "    net_model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    gen_model.eval()\n",
    "    net_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, tabular_data, labels = data['image'].to(device), data['tabular'].to(device), data['label'].to(device)\n",
    "\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "\n",
    "            gen_params = gen_model(images)\n",
    "            output = net_model(tabular_data, gen_params)\n",
    "            \n",
    "            \n",
    "            max_results = torch.max(output, dim= -1)\n",
    "            predicted = max_results.indices\n",
    "\n",
    "            y_test.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "#             predicted = torch.squeeze(predicted)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             predicted = torch.round(predicted)\n",
    "#             # print(predicted.shape)\n",
    "#             lb = labels.tolist()\n",
    "#             pr = predicted.tolist()\n",
    "#             y_test.extend(lb)\n",
    "#             y_pred.extend(pr)\n",
    "    \n",
    "    arr_accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n",
    "    return arr_accuracy, scores\n",
    "\n",
    "\n",
    "#     print(confusion_matrix(y_test,y_pred))\n",
    "#     print(classification_report(y_test,y_pred))\n",
    "#     print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "## Pure MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3754c14f-e04c-4903-8aa3-4695b8d2f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1: running loss: 3.82016, validation loss: 1511.83480\n",
      "epoch  2: running loss: 3.36674, validation loss: 2.20859\n",
      "epoch  3: running loss: 1.84525, validation loss: 3.33905\n",
      "epoch  4: running loss: 1.89570, validation loss: 1.83640\n",
      "epoch  5: running loss: 1.57828, validation loss: 1.53344\n",
      "epoch  6: running loss: 1.44709, validation loss: 1.38590\n",
      "epoch  7: running loss: 1.30745, validation loss: 1.17459\n",
      "epoch  8: running loss: 1.10829, validation loss: 1.07993\n",
      "epoch  9: running loss: 0.95354, validation loss: 1.04543\n",
      "epoch 10: running loss: 0.95695, validation loss: 1.47651\n",
      "epoch 11: running loss: 1.11262, validation loss: 1.28142\n",
      "epoch 12: running loss: 1.29895, validation loss: 1.30649\n",
      "epoch 13: running loss: 1.22276, validation loss: 1.19594\n",
      "epoch 14: running loss: 0.83456, validation loss: 0.92169\n",
      "epoch 15: running loss: 0.59939, validation loss: 0.87190\n",
      "epoch 16: running loss: 0.70287, validation loss: 1.48153\n",
      "epoch 17: running loss: 0.77317, validation loss: 0.85644\n",
      "epoch 18: running loss: 0.41226, validation loss: 0.71471\n",
      "epoch 19: running loss: 0.39336, validation loss: 1.50697\n",
      "epoch 20: running loss: 0.64640, validation loss: 2.20608\n",
      "epoch 21: running loss: 0.55743, validation loss: 0.87586\n",
      "epoch 22: running loss: 0.37964, validation loss: 0.55682\n",
      "epoch 23: running loss: 0.35123, validation loss: 0.62163\n",
      "epoch 24: running loss: 0.25457, validation loss: 0.47651\n",
      "epoch 25: running loss: 0.12727, validation loss: 0.50937\n",
      "epoch 26: running loss: 0.10537, validation loss: 0.48416\n",
      "epoch 27: running loss: 0.17511, validation loss: 0.59446\n",
      "epoch 28: running loss: 0.09882, validation loss: 1.09198\n",
      "epoch 29: running loss: 0.18869, validation loss: 1.29079\n",
      "epoch 30: running loss: 0.58214, validation loss: 0.94109\n",
      "Finished Training\n",
      "epoch 24 model selected\n",
      "iteration 1 elapsed time: 83.59822845458984, accuracy : 0.8652\n",
      "epoch  1: running loss: 2.86158, validation loss: 1207.41720\n",
      "epoch  2: running loss: 2.87611, validation loss: 11.59708\n",
      "epoch  3: running loss: 1.91288, validation loss: 1.85287\n",
      "epoch  4: running loss: 1.70078, validation loss: 1.63583\n",
      "epoch  5: running loss: 1.58943, validation loss: 1.47067\n",
      "epoch  6: running loss: 1.50342, validation loss: 1.43276\n",
      "epoch  7: running loss: 1.33305, validation loss: 1.19094\n",
      "epoch  8: running loss: 1.25432, validation loss: 1.17869\n",
      "epoch  9: running loss: 1.02753, validation loss: 0.98938\n",
      "epoch 10: running loss: 0.89088, validation loss: 1.06158\n",
      "epoch 11: running loss: 1.08079, validation loss: 1.24621\n",
      "epoch 12: running loss: 0.88882, validation loss: 1.06022\n",
      "epoch 13: running loss: 0.73739, validation loss: 0.73016\n",
      "epoch 14: running loss: 0.54110, validation loss: 0.64906\n",
      "epoch 15: running loss: 1.47371, validation loss: 3.27411\n",
      "epoch 16: running loss: 1.30582, validation loss: 12.89307\n",
      "epoch 17: running loss: 2.06569, validation loss: 1.53432\n",
      "epoch 18: running loss: 1.26315, validation loss: 12.77969\n",
      "epoch 19: running loss: 0.92817, validation loss: 0.88516\n",
      "epoch 20: running loss: 0.67479, validation loss: 0.66655\n",
      "epoch 21: running loss: 0.55213, validation loss: 0.53266\n",
      "epoch 22: running loss: 0.75758, validation loss: 1.07437\n",
      "epoch 23: running loss: 0.68590, validation loss: 0.60184\n",
      "epoch 24: running loss: 1.15322, validation loss: 1.04523\n",
      "epoch 25: running loss: 0.70202, validation loss: 0.69217\n",
      "epoch 26: running loss: 0.52641, validation loss: 0.49019\n",
      "epoch 27: running loss: 0.44147, validation loss: 0.49900\n",
      "epoch 28: running loss: 0.34406, validation loss: 0.42636\n",
      "epoch 29: running loss: 0.37205, validation loss: 0.31366\n",
      "epoch 30: running loss: 0.24830, validation loss: 0.32699\n",
      "Finished Training\n",
      "epoch 29 model selected\n",
      "iteration 2 elapsed time: 80.99555706977844, accuracy : 0.8536\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 2\n",
    "results = np.zeros([max_iterations, num_classes*4 + 1])\n",
    "# trainloader, testloader = prepare_dataloader(full_dataset)\n",
    "\n",
    "for it in range(max_iterations):\n",
    "    start = time.time()\n",
    "    \n",
    "    # mlp\n",
    "#     epoch_loss_mlp = train_mlp(trainloader,testloader, print_epochs = True, loss_fn = nn.CrossEntropyLoss())\n",
    "#     acc, scores = test_mlp(epoch_loss_mlp, print_model_epoch = True)\n",
    "    \n",
    "    #     # ------- mlp-resnet film \n",
    "    epoch_loss = train_model(trainloader, testloader, print_epochs=True, loss_fn = nn.CrossEntropyLoss())\n",
    "    acc, scores = test_model(epoch_loss, print_model_epoch = True)\n",
    "    \n",
    "    # scores = precision, recall, fscore, support\n",
    "    results[it, 0] = acc\n",
    "    \n",
    "    for j, score in enumerate(scores):\n",
    "        start_ind = 1 + j*num_classes\n",
    "        results[it, start_ind: start_ind + num_classes] = score\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print('iteration {} elapsed time: {}, accuracy : {}'.format(it+1, end-start, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dab4baa9-6367-4e7b-bdc3-f9581d960491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.942761</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.959844</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986935</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.985214</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944840</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.970309</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688882</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.595770</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.644839</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.682368</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.802765</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.680926</td>\n",
       "      <td>0.7925</td>\n",
       "      <td>0.727814</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.992983</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.992490</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.983559</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.991642</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.983960</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.957551</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall        f1  support\n",
       "0   0.942761  0.9780  0.959844   1000.0\n",
       "1   0.986935  0.9835  0.985214   1000.0\n",
       "2   0.944840  0.9990  0.970309   1000.0\n",
       "3   0.688882  0.5555  0.595770   1000.0\n",
       "4   0.644839  0.7475  0.682368   1000.0\n",
       "5   0.802765  0.6125  0.690385   1000.0\n",
       "6   0.680926  0.7925  0.727814   1000.0\n",
       "7   0.992983  0.9920  0.992490   1000.0\n",
       "8   0.983559  1.0000  0.991642   1000.0\n",
       "9   0.983960  0.9335  0.957551   1000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.036172</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055160</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.028690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.117082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075733</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058346</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007849</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.045996</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016040</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall        f1  support\n",
       "0   0.049303  0.0220  0.036172      0.0\n",
       "1   0.013065  0.0145  0.013785      0.0\n",
       "2   0.055160  0.0010  0.028690      0.0\n",
       "3   0.006356  0.1905  0.117082      0.0\n",
       "4   0.075733  0.0925  0.003855      0.0\n",
       "5   0.058346  0.0545  0.013201      0.0\n",
       "6   0.007849  0.1175  0.045996      0.0\n",
       "7   0.005019  0.0070  0.006011      0.0\n",
       "8   0.016441  0.0000  0.008358      0.0\n",
       "9   0.016040  0.0585  0.038433      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.8593999999999999, std: 0.005799999999999972\n"
     ]
    }
   ],
   "source": [
    "def display_table(scores):\n",
    "    df = np.reshape(scores, [num_classes,4], order ='F')\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    # df.style.set_table_attributes(\"style='display:inline'\").set_caption(mode)\n",
    "    \n",
    "    df.columns = ['precision', 'recall', 'f1', 'support']\n",
    "    # df.index = ['unfrozen', 'frozen']\n",
    "    # df.index = ['Visible ice', 'No visible ice']\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "def display_results(results):\n",
    "    mean = np.mean(results, axis=0)\n",
    "    std = np.std(results, axis=0)\n",
    "    \n",
    "    print(\"mean\")\n",
    "    display_table(mean[1:])\n",
    "    \n",
    "    print(\"std\")\n",
    "    display_table(std[1:])\n",
    "    \n",
    "    print(\"Accuracy mean: {}, std: {}\".format(mean[0], std[0]))\n",
    "\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207e12e-9450-4b08-ab11-ddd2554e3561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
