{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6afa8bd-2e17-47ff-b378-62d1ce7b7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filmModels import *\n",
    "from dataPreprocess import *\n",
    "from filmPostProcess import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a1f5dce-49bd-40bd-85ea-ae3d6149640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_interpolated = np.load('components_analysis/bh_observations.npy').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51c2830-42c2-4e0e-9f97-d93dd0db9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('components_analysis/df_unique.csv', header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1897fdb6-da3e-4a0d-b188-abd8edec3b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_interpolated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a641e19-cfbf-415e-8dcc-e508ff784bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = np.load('components_analysis/sources_n3.npy')\n",
    "mixes = np.load('components_analysis/mix_n3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7432459-3a4d-4143-9244-141dbab8ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_class = np.argmax(mixes, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3980f36-0831-42f3-a5f8-f03d73604b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e7080-464a-4973-861e-a5e37e5620a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"saga_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc2050-00fc-48e7-b856-560b107908ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, testloader, print_epochs = False, loss_fn = torch.nn.BCELoss()):\n",
    "    \n",
    "    model= models.resnet18()\n",
    "    model.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=n_components)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay = L2_param)\n",
    "\n",
    "    epoch_loss = np.zeros([train_max_epoch, 2])\n",
    "    for epoch in range(train_max_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        model.train()\n",
    "        running_loss_sum = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            image, labels = data['image'].to(device), data['components_strengths'].to(device)\n",
    "\n",
    "            predicted = model(image)\n",
    "            \n",
    "            \n",
    "#             print(predicted.squeeze().get_device())\n",
    "#             print('\\n')\n",
    "#             print(labels.get_device())\n",
    "            \n",
    "            \n",
    "            # squeeze: return tensor with all dimensions of size 1 removed\n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_sum += loss.item()\n",
    "\n",
    "        # ----------- get validation loss for current epoch --------------\n",
    "        model.eval()\n",
    "        validation_loss_sum = 0.0\n",
    "        for i, data in enumerate(testloader, 0): # loop over each sample\n",
    "\n",
    "            image, labels = data['image'].to(device), data['components_strengths'].to(device)\n",
    "\n",
    "            predicted = model(image)\n",
    "            \n",
    "            loss = loss_fn(predicted.squeeze(), labels)\n",
    "\n",
    "            validation_loss_sum += loss.item()\n",
    "\n",
    "        # ---------------- print statistics ------------------------\n",
    "\n",
    "        running_loss = running_loss_sum / len(trainloader)\n",
    "        validation_loss = validation_loss_sum / len(testloader)\n",
    "        epoch_loss[epoch, :] =  [running_loss, validation_loss]\n",
    "        \n",
    "        if print_epochs:\n",
    "            print('epoch %2d: running loss: %.5f, validation loss: %.5f' %\n",
    "                          (epoch + 1, running_loss, validation_loss))\n",
    "        \n",
    "        torch.save(model.state_dict(), os.path.join(models_dir, 'epoch-{}.pt'.format(epoch+1)))\n",
    "    \n",
    "    if print_epochs:\n",
    "        print('Finished Training')\n",
    "        \n",
    "    return epoch_loss\n",
    "        \n",
    "def test(epoch_loss, print_model_epoch = False):\n",
    "    \n",
    "    # ------ select model ---------\n",
    "    ind = np.argmin(epoch_loss[:, 1])\n",
    "    \n",
    "    \n",
    "    model= models.resnet18()\n",
    "    model.conv1 = nn.Conv2d(n_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=n_components)\n",
    "    \n",
    "    model.load_state_dict(torch.load('{}epoch-{}.pt'.format(models_dir, ind+1)))\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    if print_model_epoch:\n",
    "        print(\"epoch {} model selected\".format(ind+1))\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        res_strengths = []\n",
    "        \n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            image, labels = data['image'].to(device), data['components_strengths'].to(device)\n",
    "            # y_test.append(label.numpy().list())\n",
    "            # print(label.shape)\n",
    "            # print(images.shape)\n",
    "\n",
    "            output = model(image)\n",
    "            \n",
    "            res_strengths.extend(output)\n",
    "            \n",
    "    return res_strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00642597-1338-4803-8987-9aa7622befed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "# batchsize can cause error when last leftover batchsize is 1, batchnorm cannot function on 1 sample data\n",
    "batchsize = 20\n",
    "while(train_size % batchsize == 1):\n",
    "    batchsize+=1\n",
    "print(batchsize)\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9df36e-2ceb-4483-902c-2fde757200a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer_gen = shap.DeepExplainer(model, train_images)\n",
    "shap_values = explainer_gen.shap_values(test_images)\n",
    "shap_pixels = np.mean(np.mean(abs(shap_values), -1), -1)\n",
    "shap_samples = np.mean(shap_pixels, 1)\n",
    "shap_channel = np.mean(shap_samples, -1) # averaged over classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
