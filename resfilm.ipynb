{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028d0170-40b7-430d-8cd3-92aa3e301d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e284fc-e9cc-4908-9594-fec4230cbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    # same as Conv2d but with padding\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs) # super() : inherit from baseclass\n",
    "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
    "        self.blocks = nn.Identity()\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut:\n",
    "            residual = self.shortcut(x)\n",
    "        # print(residual.shape)\n",
    "        x = self.blocks(x)\n",
    "        # print(x.shape)\n",
    "        x += residual # shapes of x and residual don't match when expansion > 1 and self.blocks = nn.Identity()\n",
    "        return x\n",
    "    \n",
    "    @property # use method like attribute with \".\" syntax\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "    \n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(OrderedDict(\n",
    "        {\n",
    "            # Conv2d expects the input to be of shape [batch_size, input_channels, input_height, input_width]\n",
    "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            \n",
    "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
    "        })) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0e9eb3-3502-4fff-b4b2-298fad2196c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ResidualBlock\n",
    "block = ResidualBlock(1,2)\n",
    "block(torch.tensor([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de6ff11-f133-45fb-b876-b0b0a05a8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ResNetResidualBlock ??\n",
    "# x = torch.tensor([[[[1.0, 1.1]]]])\n",
    "# block = ResNetResidualBlock(1,1, expansion=2)\n",
    "# block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1266f6-4a96-4fcb-83d3-98fb48bc0512",
   "metadata": {},
   "source": [
    "### Add film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d672e22f-4fc7-445d-a57b-acca723701aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(mlp, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.output_size = output_size\n",
    "            \n",
    "            self.hidden_size = 30\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size,self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.sigmoid = torch.nn.Sigmoid() ## sigmoid for multi-label, softmax for multi-class (mutually exclusive)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            out = self.fc2(out)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            out = self.fc2(out)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            out = self.fc2(out)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            out = self.fc3(out)\n",
    "            out = self.sigmoid(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc4e2ea4-38e0-414f-a5ca-dd6834169e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, gamma, beta, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs) # super() : inherit from baseclass\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # gammas = gammas.unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        # betas = betas.unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        gamma = self.gamma.expand_as(x)\n",
    "        beta = self.beta.expand_as(x)\n",
    "        \n",
    "        return (gamma * x) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2009eec-c739-4a08-ac03-393c1170e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n",
    "                                      'bn': nn.BatchNorm2d(out_channels)\n",
    "                                      # 'film': FiLM(gamma, beta)\n",
    "                                     }))\n",
    "\n",
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            # self.conv = conv3x3\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation(),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )\n",
    "\n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, film=self.film, kernel_size=1),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, film=self.film, kernel_size=3, stride=self.downsampling),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, film=self.film, kernel_size=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32311099-7895-48a4-a23f-a31d73037f90",
   "metadata": {},
   "source": [
    "### Finish building resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdc899a-351f-412e-bf7a-148cf7ffaa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    # def __init__(self, in_channels, out_channels, gamma, beta, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "    \n",
    "    # def forward(self, x, gamma, beta)\n",
    "    def forward(self, x): #gamma beta\n",
    "        x = self.blocks(x)\n",
    "        # x = FiLM(x, gamma, beta)\n",
    "        return x\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet encoder composed by increasing different layers with increasing features.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,  *args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        # gammas[:, num_block, block_dim]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "class ResnetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "        # self.module_dim = \n",
    "        \n",
    "    # def forward(self, x, film):\n",
    "    def forward(self, x):\n",
    "        # gammas, betas = torch.split(film[:,:,:2*self.module_dim], self.module_dim, dim=-1)\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "def resnet18(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n",
    "\n",
    "def resnet34(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet50(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet101(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n",
    "\n",
    "def resnet152(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bc558-a3f6-4099-b9f5-a06b4cb5da6c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb15bead-bc16-4f1a-93bf-be2781d8c628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2837\n",
      "566\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_stephen_fix_header.csv', header=[0])\n",
    "# convert timecodes to year and month columns\n",
    "datetimes = pd.to_datetime(df['time'])\n",
    "df['month'] = datetimes.dt.month\n",
    "df['year'] = datetimes.dt.year\n",
    "\n",
    "print(df.shape[0])\n",
    "print(df['borehole'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00d46633-ad73-422c-921d-f507d53948cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>borehole</th>\n",
       "      <th>depth</th>\n",
       "      <th>frozen</th>\n",
       "      <th>cryostructures</th>\n",
       "      <th>visible_ice</th>\n",
       "      <th>ASTM_2488</th>\n",
       "      <th>materials</th>\n",
       "      <th>organic_cover</th>\n",
       "      <th>top_of_interval</th>\n",
       "      <th>bottom_of_interval</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOPSOIL</td>\n",
       "      <td>Organics</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pure ice</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Ice</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>SW-SM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.16162</td>\n",
       "      <td>-133.08682</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>GW-GM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.16105</td>\n",
       "      <td>-133.08880</td>\n",
       "      <td>2012-03-21T00:00:00Z</td>\n",
       "      <td>0170-1-12</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>Nf</td>\n",
       "      <td>No visible ice</td>\n",
       "      <td>GP-GM</td>\n",
       "      <td>Coarse till</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude                  time   borehole  depth  frozen  \\\n",
       "0  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   0.15       0   \n",
       "1  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   0.85       1   \n",
       "2  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   1.90       1   \n",
       "3  69.16162 -133.08682  2012-03-21T00:00:00Z  0170-1-10   5.40       1   \n",
       "4  69.16105 -133.08880  2012-03-21T00:00:00Z  0170-1-12   1.20       1   \n",
       "\n",
       "  cryostructures     visible_ice ASTM_2488    materials  organic_cover  \\\n",
       "0            NaN             NaN   TOPSOIL     Organics            0.3   \n",
       "1            NaN        Pure ice       ICE          Ice            0.3   \n",
       "2             Nf  No visible ice     SW-SM  Coarse till            0.3   \n",
       "3             Nf  No visible ice     GW-GM  Coarse till            0.3   \n",
       "4             Nf  No visible ice     GP-GM  Coarse till            0.0   \n",
       "\n",
       "   top_of_interval  bottom_of_interval  month  year  \n",
       "0              0.0                 0.3      3  2012  \n",
       "1              0.3                 1.4      3  2012  \n",
       "2              1.4                 2.4      3  2012  \n",
       "3              2.4                 8.4      3  2012  \n",
       "4              0.0                 2.4      3  2012  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c10c7250-0472-44f5-a184-3ccf83ab24de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['frozen'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6635439-f35d-4d3e-9e28-9c1730065d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Geo90Dataset(Dataset):\n",
    "    def __init__(self, data_root, df, base_lat, base_lng, chip_size=20, label_name = 'frozen'):\n",
    "        \n",
    "        self.base_lat = base_lat\n",
    "        self.base_lng = base_lng\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        self.chip_size = chip_size\n",
    "        self.label_name = label_name\n",
    "        \n",
    "        self.trans = transforms.ToTensor()\n",
    "        \n",
    "        self.preloaded = torch.zeros(26, 6000, 6000)\n",
    "        \n",
    "        for i, file in enumerate(os.listdir(\"geomorph_data\")):\n",
    "            # name = file.split('_')[0]\n",
    "            # print(name)\n",
    "            self.preloaded[i] = self.trans(Image.open(\"geomorph_data/\" + file))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        bh_id = row.at['borehole']\n",
    "        lat = row.at['latitude']\n",
    "        lng = row.at['longitude']\n",
    "        \n",
    "\n",
    "        pixel_len = 5/6000\n",
    "        \n",
    "\n",
    "        lat_index_start = np.round((self.base_lat - lat) / pixel_len - self.chip_size/2).astype(int)\n",
    "        lat_index_end = lat_index_start + self.chip_size\n",
    "        \n",
    "        lng_index_start = np.round((lng - self.base_lng) / pixel_len - self.chip_size/2).astype(int)\n",
    "        lng_index_end = lng_index_start + self.chip_size\n",
    "        \n",
    "        image = self.preloaded[:, lat_index_start:lat_index_end,lng_index_start:lng_index_end]\n",
    "        \n",
    "        \n",
    "        surface = torch.tensor(row.filter(['latitude', 'longitude', 'year', 'month', 'depth']))\n",
    "        \n",
    "        return {'image': image, 'surface_data': surface, 'frozen': row.at['frozen']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4d35c1-21ec-4e70-99ed-44192dd6f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lat = 70\n",
    "base_lng = -135\n",
    "\n",
    "full_dataset = Geo90Dataset(\"geomorph_data\", df, base_lat, base_lng, chip_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f971e-5349-40fb-bcb6-4d2d246376f2",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a76a7a-78da-4083-99bc-d6c1a11788a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "training_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "batchsize = 20\n",
    "\n",
    "trainloader = DataLoader(training_data, batch_size=batchsize, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a001e43-428b-4e44-85c3-2f5f807a6f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] running loss: 1.12174\n",
      "[1,    40] running loss: 0.51285\n",
      "[1,    60] running loss: 0.40280\n",
      "[1,    80] running loss: 0.38432\n",
      "[1,   100] running loss: 0.40581\n",
      "[2,    20] running loss: 0.43695\n",
      "[2,    40] running loss: 0.38143\n",
      "[2,    60] running loss: 0.33936\n",
      "[2,    80] running loss: 0.46175\n",
      "[2,   100] running loss: 0.37115\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "film_gen = mlp()\n",
    "gen_optimizer = torch.optim.Adam(film_gen.parameters())\n",
    "\n",
    "film_net = resnet18(26, 2)\n",
    "net_optimizer = torch.optim.Adam(film_net.parameters())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): # loop over each sample\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        images, surface_data, labels = data['image'], data['surface_data'], data['frozen']\n",
    "        \n",
    "        # TODO: exammine film_params gradients / readup pytorch\n",
    "        film_params = film_gen(surface_data)\n",
    "        predicted = film_net(images, film_params)\n",
    "\n",
    "        # predicted = film_net(images)\n",
    "        loss = loss_fn(predicted, labels)\n",
    "\n",
    "        gen_optimizer.zero_grad()\n",
    "        net_optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        gen_optimizer.step()\n",
    "        net_optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        print_interval = 20\n",
    "        running_loss += loss.item()\n",
    "        if i % print_interval == print_interval-1:    # print every $print_interval mini-batches\n",
    "            print('[%d, %5d] running loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / print_interval))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0e1d496-eefa-4f41-b36e-edc4ed434bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(film_net, 'film_net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d729957-6c32-4129-a115-2a48d8455372",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f682fd4-19e7-403c-a333-626415bfeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    images, surface_data, label = data['image'], data['surface_data'], data['frozen']\n",
    "    \n",
    "    # y_test.append(label.numpy().list())\n",
    "    # print(label.shape)\n",
    "    # print(images.shape)\n",
    "    outputs = film_net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    # print(predicted.shape)\n",
    "    lb = label.tolist()\n",
    "    pd = predicted.tolist()\n",
    "    y_test.extend(lb)\n",
    "    y_pred.extend(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f55d62-1e48-4d86-b07f-164f19d9d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  77]\n",
      " [  0 491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        77\n",
      "           1       0.86      1.00      0.93       491\n",
      "\n",
      "    accuracy                           0.86       568\n",
      "   macro avg       0.43      0.50      0.46       568\n",
      "weighted avg       0.75      0.86      0.80       568\n",
      "\n",
      "0.8644366197183099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\mouju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "660b543b-9b4c-4710-8576-0c8f6ff2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(40).reshape(5,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e07c6ba-2cdb-4c2e-afd8-4d857f818ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c = torch.split(a, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac3bad82-2c43-40a4-8ce8-03332e3e645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a986b6f-6fe1-4c77-ac45-390a4e0b7e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "733d8808-fdf0-49c4-81a8-50b19dd23c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 128), (128, 256), (256, 512)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_sizes=[64, 128, 256, 512]\n",
    "list(zip(blocks_sizes, blocks_sizes[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a90cd-71e9-4b95-adbf-4743a89c76d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
